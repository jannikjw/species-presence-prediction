{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GLC'...\n",
      "remote: Enumerating objects: 383, done.\u001b[K\n",
      "remote: Counting objects: 100% (228/228), done.\u001b[K\n",
      "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
      "remote: Total 383 (delta 119), reused 170 (delta 63), pack-reused 155\u001b[K\n",
      "Receiving objects: 100% (383/383), 10.57 MiB | 37.32 MiB/s, done.\n",
      "Resolving deltas: 100% (205/205), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf GLC\n",
    "!git clone https://github.com/maximiliense/GLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-1n5ck6bk because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Add, GlobalAveragePooling2D, Conv2D, Dense, AveragePooling2D, \\\n",
    "BatchNormalization, Normalization, Dropout, Flatten, Lambda, Input, Activation\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import schedules, SGD\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import backend as K\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import scale\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import copy\n",
    "import threading\n",
    "import opendatasets as od\n",
    "\n",
    "%pylab inline --no-import-all\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from GLC.data_loading.common import load_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\"username\":\"nathaliemh\",\"key\":\"cba80d1f619e96b238e4a95aa3017836\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data = od.download(\"https://www.kaggle.com/competitions/geolifeclef-2022-lifeclef-2022-fgvc9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this path to adapt to where you downloaded the data\n",
    "DATA_PATH = Path(\"./geolifeclef-2022-lifeclef-2022-fgvc9/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmetadata\u001b[0m/      \u001b[01;34mpatches-fr\u001b[0m/  \u001b[01;34mpatches_sample\u001b[0m/  \u001b[01;34mrasters\u001b[0m/\r\n",
      "\u001b[01;34mobservations\u001b[0m/  \u001b[01;34mpatches-us\u001b[0m/  \u001b[01;34mpre-extracted\u001b[0m/   sample_submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls -L $DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observations_fr_test.csv   observations_us_test.csv\r\n",
      "observations_fr_train.csv  observations_us_train.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls $DATA_PATH/observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for training: 1627475\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>species_id</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10561949</th>\n",
       "      <td>45.705116</td>\n",
       "      <td>1.424622</td>\n",
       "      <td>241</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10131188</th>\n",
       "      <td>45.146973</td>\n",
       "      <td>6.416794</td>\n",
       "      <td>101</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799362</th>\n",
       "      <td>46.783695</td>\n",
       "      <td>-2.072855</td>\n",
       "      <td>700</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10392536</th>\n",
       "      <td>48.604866</td>\n",
       "      <td>-2.825003</td>\n",
       "      <td>1456</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10335049</th>\n",
       "      <td>48.815567</td>\n",
       "      <td>-0.161431</td>\n",
       "      <td>157</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 latitude  longitude  species_id subset\n",
       "observation_id                                         \n",
       "10561949        45.705116   1.424622         241  train\n",
       "10131188        45.146973   6.416794         101  train\n",
       "10799362        46.783695  -2.072855         700  train\n",
       "10392536        48.604866  -2.825003        1456  train\n",
       "10335049        48.815567  -0.161431         157  train"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Training Dataset ###\n",
    "# let's load the data from file\n",
    "df_obs_fr = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "\n",
    "df_obs = pd.concat((df_obs_fr, df_obs_us))\n",
    "\n",
    "print(\"Number of observations for training: {}\".format(len(df_obs)))\n",
    "\n",
    "# let's have a look at the data\n",
    "df_obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for testing: 36421\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10782781</th>\n",
       "      <td>43.601788</td>\n",
       "      <td>6.940195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10364138</th>\n",
       "      <td>46.241711</td>\n",
       "      <td>0.683586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10692017</th>\n",
       "      <td>45.181095</td>\n",
       "      <td>1.533459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10222322</th>\n",
       "      <td>46.938450</td>\n",
       "      <td>5.298678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10241950</th>\n",
       "      <td>45.017433</td>\n",
       "      <td>0.960736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 latitude  longitude\n",
       "observation_id                      \n",
       "10782781        43.601788   6.940195\n",
       "10364138        46.241711   0.683586\n",
       "10692017        45.181095   1.533459\n",
       "10222322        46.938450   5.298678\n",
       "10241950        45.017433   0.960736"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test Dataset ###\n",
    "df_obs_fr_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "\n",
    "df_obs_test = pd.concat((df_obs_fr_test, df_obs_us_test))\n",
    "\n",
    "print(\"Number of observations for testing: {}\".format(len(df_obs_test)))\n",
    "\n",
    "df_obs_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   landcover_code  suggested_landcover_code suggested_landcover_label\n",
      "0               0                         0              Missing Data\n",
      "1               1                        11          Cultivated Crops\n",
      "2               2                        11          Cultivated Crops\n",
      "3               3                         6       Broad-leaved Forest\n",
      "4               4                         7         Coniferous Forest\n"
     ]
    }
   ],
   "source": [
    "df_suggested_landcover_alignment = pd.read_csv(DATA_PATH / \"metadata\" / \"landcover_suggested_alignment.csv\", sep=\";\")\n",
    "print(df_suggested_landcover_alignment.head())\n",
    "landcover_mapping = df_suggested_landcover_alignment[\"suggested_landcover_code\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val Split Labels\n",
    "Retrieve the train/val split provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1587395 (97.5% of train observations)\n",
      "Validation set size: 40080 (2.5% of train observations)\n"
     ]
    }
   ],
   "source": [
    "obs_id_train = df_obs.index[df_obs[\"subset\"] == \"train\"].values\n",
    "obs_id_val = df_obs.index[df_obs[\"subset\"] == \"val\"].values\n",
    "\n",
    "#obs_id_train = obs_id_train[:int(len(obs_id_train)/3)]\n",
    "\n",
    "y_train = df_obs.loc[obs_id_train][\"species_id\"].values\n",
    "y_val = df_obs.loc[obs_id_val][\"species_id\"].values\n",
    "\n",
    "n_val = len(obs_id_val)\n",
    "print(\"Training set size: {} ({:.1%} of train observations)\".format(len(y_train), len(y_train) / len(df_obs)))\n",
    "print(\"Validation set size: {} ({:.1%} of train observations)\".format(n_val, n_val / len(df_obs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1587395\n"
     ]
    }
   ],
   "source": [
    "print(len(obs_id_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obs_id_train[int(1587395*0.99986):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17031"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# load training dataset samples\\n# factor = 1 means load full training dataset\\n# factor = 100 means load 1/100 of the full dataset\\nfactor = 1\\nlast_print = time.time()\\n\\n#X_train = list() #np.array((np.shape(y_train), 256, 256, 3))\\nX_train = np.zeros((len(obs_id_train), 256, 256, 3))\\nfor i in range(len(obs_id_train)):\\n    obs_id = obs_id_train[i]\\n    \\n    patch = load_patch(obs_id, DATA_PATH, landcover_mapping=landcover_mapping, data=\\'rgb\\')\\n    #X_train.append(patch[0])\\n    X_train[i] = patch[0]\\n    \\n    #percent_progress = len(X_train)/(len(y_train)/factor) * 100\\n    percent_progress = i/(len(y_train)/factor) * 100\\n    \\n    if time.time() - last_print > 1:\\n        sys.stdout.write(\\'\\r\\')\\n        # the exact output you\\'re looking for:\\n        sys.stdout.write(\"[%-20s] %.3f%%\" % (\\'=\\'*int(percent_progress/5), percent_progress))\\n        sys.stdout.flush()\\n        last_print = time.time()\\n        \\n    #if len(X_train) >= (len(y_train)/factor):\\n    #if percent_progress >= 99.98:\\n    #    break\\nprint(\"done with loading\")\\n    \\nX_train = np.array(X_train)\\nprint(\"sample array shape: \", np.shape(X_train))\\nprint(\"label array shape: \", np.shape(y_train))\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# load training dataset samples\n",
    "# factor = 1 means load full training dataset\n",
    "# factor = 100 means load 1/100 of the full dataset\n",
    "factor = 1\n",
    "last_print = time.time()\n",
    "\n",
    "#X_train = list() #np.array((np.shape(y_train), 256, 256, 3))\n",
    "X_train = np.zeros((len(obs_id_train), 256, 256, 3))\n",
    "for i in range(len(obs_id_train)):\n",
    "    obs_id = obs_id_train[i]\n",
    "    \n",
    "    patch = load_patch(obs_id, DATA_PATH, landcover_mapping=landcover_mapping, data='rgb')\n",
    "    #X_train.append(patch[0])\n",
    "    X_train[i] = patch[0]\n",
    "    \n",
    "    #percent_progress = len(X_train)/(len(y_train)/factor) * 100\n",
    "    percent_progress = i/(len(y_train)/factor) * 100\n",
    "    \n",
    "    if time.time() - last_print > 1:\n",
    "        sys.stdout.write('\\r')\n",
    "        # the exact output you're looking for:\n",
    "        sys.stdout.write(\"[%-20s] %.3f%%\" % ('='*int(percent_progress/5), percent_progress))\n",
    "        sys.stdout.flush()\n",
    "        last_print = time.time()\n",
    "        \n",
    "    #if len(X_train) >= (len(y_train)/factor):\n",
    "    #if percent_progress >= 99.98:\n",
    "    #    break\n",
    "print(\"done with loading\")\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "print(\"sample array shape: \", np.shape(X_train))\n",
    "print(\"label array shape: \", np.shape(y_train))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train[:]))\n",
    "#train_ds = train_ds.batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write patches and labels to TFRecord\n",
    "This only needs to be done once to obtain a TFRecord file. This file then can be reused during future runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.train.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def image_tfexample(img, label):\\n    image_shape = img.shape\\n\\n    feature = {\\n      'height': _int64_feature(image_shape[0]),\\n      'width': _int64_feature(image_shape[1]),\\n      'depth': _int64_feature(image_shape[2]),\\n      'label': _int64_feature(label),\\n      'image_raw': _bytes_feature(img.tobytes()),\\n    }\\n    \\n    return tf.train.Example(features=tf.train.Features(feature=feature))\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary with features that may be relevant.\n",
    "\"\"\"def image_tfexample(img, label):\n",
    "    image_shape = img.shape\n",
    "\n",
    "    feature = {\n",
    "      'height': _int64_feature(image_shape[0]),\n",
    "      'width': _int64_feature(image_shape[1]),\n",
    "      'depth': _int64_feature(image_shape[2]),\n",
    "      'label': _int64_feature(label),\n",
    "      'image_raw': _bytes_feature(img.tobytes()),\n",
    "    }\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def writeToTFRecord(obs_ids, labels, record_file):\\n    \\n    counter = 0\\n    last_print = time.time()\\n    \\n    options = tf.io.TFRecordOptions(compression_type = \\'GZIP\\')\\n    \\n    with tf.io.TFRecordWriter(record_file, options=options) as writer:\\n        for obs_id, label in zip(obs_ids, labels):\\n            patch = load_patch(obs_id, DATA_PATH)\\n\\n            # convert single rgb image + label to tf example\\n            tf_example = image_tfexample(patch[0], label)\\n\\n            # write to records file\\n            writer.write(tf_example.SerializeToString())\\n            counter += 1\\n\\n            if time.time() - last_print > 1:\\n                percent_progress = counter/len(labels) * 100\\n                sys.stdout.write(\\'\\r\\')\\n                sys.stdout.write(\"[%-20s] %.3f%%\" % (\\'=\\'*int(percent_progress/5), percent_progress))\\n                sys.stdout.flush()\\n                last_print = time.time()\\n                \\n            if counter > 10000:\\n                break\\n            \\n    return counter'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the raw image files to a TFRecord file (record_file).\n",
    "# First, process all images into `tf.train.Example` messages.\n",
    "# Then, write to a `.tfrecords` file.   \n",
    "\"\"\"def writeToTFRecord(obs_ids, labels, record_file):\n",
    "    \n",
    "    counter = 0\n",
    "    last_print = time.time()\n",
    "    \n",
    "    options = tf.io.TFRecordOptions(compression_type = 'GZIP')\n",
    "    \n",
    "    with tf.io.TFRecordWriter(record_file, options=options) as writer:\n",
    "        for obs_id, label in zip(obs_ids, labels):\n",
    "            patch = load_patch(obs_id, DATA_PATH)\n",
    "\n",
    "            # convert single rgb image + label to tf example\n",
    "            tf_example = image_tfexample(patch[0], label)\n",
    "\n",
    "            # write to records file\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "            counter += 1\n",
    "\n",
    "            if time.time() - last_print > 1:\n",
    "                percent_progress = counter/len(labels) * 100\n",
    "                sys.stdout.write('\\r')\n",
    "                sys.stdout.write(\"[%-20s] %.3f%%\" % ('='*int(percent_progress/5), percent_progress))\n",
    "                sys.stdout.flush()\n",
    "                last_print = time.time()\n",
    "                \n",
    "            if counter > 10000:\n",
    "                break\n",
    "            \n",
    "    return counter\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether it has the same length as y_train\n",
    "#np.shape(obs_id_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write training dataset samples to TFrecord\n",
    "#train_record_amount = writeToTFRecord(obs_id_train, y_train, record_file = 'training.tfrecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write training dataset samples to TFrecord\n",
    "#val_record_amount = writeToTFRecord(obs_id_val, y_val, record_file = 'validation.tfrecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing Around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to TFRecords file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def image_tfexample(img, label):\\n    image_shape = img.shape\\n\\n    feature = {\\n      'height': _int64_feature(image_shape[0]),\\n      'width': _int64_feature(image_shape[1]),\\n      'depth': _int64_feature(image_shape[2]),\\n      'label': _int64_feature(label),\\n      'image_raw': _bytes_feature(img),\\n    }\\n    \\n    return tf.train.Example(features=tf.train.Features(feature=feature))\\n    \""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary with features that may be relevant.\n",
    "\"\"\"def image_tfexample(img, label):\n",
    "    image_shape = img.shape\n",
    "\n",
    "    feature = {\n",
    "      'height': _int64_feature(image_shape[0]),\n",
    "      'width': _int64_feature(image_shape[1]),\n",
    "      'depth': _int64_feature(image_shape[2]),\n",
    "      'label': _int64_feature(label),\n",
    "      'image_raw': _bytes_feature(img),\n",
    "    }\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"record_file = 'X_train.tfrecords'\\nwith tf.io.TFRecordWriter(record_file) as writer:\\n    for img, label in zip(X_train, y_train):\\n\\n        # convert single image + label to tf example\\n        img_string = np.array2string(img)\\n        tf_example = image_tfexample(img, label)\\n    \\n        # write to records file\\n        writer.write(tf_example.SerializeToString())\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the raw image files to `images.tfrecords`.\n",
    "# First, process all images into `tf.train.Example` messages.\n",
    "# Then, write to a `.tfrecords` file.\n",
    "\n",
    "\"\"\"record_file = 'X_train.tfrecords'\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    for img, label in zip(X_train, y_train):\n",
    "\n",
    "        # convert single image + label to tf example\n",
    "        img_string = np.array2string(img)\n",
    "        tf_example = image_tfexample(img, label)\n",
    "    \n",
    "        # write to records file\n",
    "        writer.write(tf_example.SerializeToString())\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read first few images from records file to ensure it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"image_feature_description = {\\n    'height': tf.io.FixedLenFeature([], tf.int64),\\n    'width': tf.io.FixedLenFeature([], tf.int64),\\n    'depth': tf.io.FixedLenFeature([], tf.int64),\\n    'label': tf.io.FixedLenFeature([], tf.int64),\\n    'image_raw': tf.io.FixedLenFeature([], tf.string),\\n}\\n\\ndef _parse_image_function(example_proto):\\n  # Parse the input tf.train.Example proto using the dictionary above.\\n  return tf.io.parse_single_example(example_proto, image_feature_description)\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary describing the features.\n",
    "\"\"\"image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image_records = tf.data.TFRecordDataset(record_file)\\nparsed_image_records = image_records.map(_parse_image_function)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"image_records = tf.data.TFRecordDataset(record_file)\n",
    "parsed_image_records = image_records.map(_parse_image_function)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for record in parsed_image_records:\\n  image_raw = record['image_raw'].numpy()\\n  display.display(display.Image(data=image_raw))\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for record in parsed_image_records:\n",
    "  image_raw = record['image_raw'].numpy()\n",
    "  display.display(display.Image(data=image_raw))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load entire dataset in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# read file\\ndataset = tf.data.TFRecordDataset(record_file)\\n\\n# parse each instance\\ndataset = dataset.map(_parse_image_function, num_parallel_calls=num_threads)\\n\\n# shuffle\\ndataset = dataset.shuffle(buffer_size)\\n\\n# form batch and epoch\\ndataset = dataset.batch(batch_size)\\ndataset = dataset.repeat(num_epoch)\\niterator = dataset.make_one_shot_iterator()\\n\\n# get a batch\\nx_batch, y_batch = self.iterator.get_next()\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# read file\n",
    "dataset = tf.data.TFRecordDataset(record_file)\n",
    "\n",
    "# parse each instance\n",
    "dataset = dataset.map(_parse_image_function, num_parallel_calls=num_threads)\n",
    "\n",
    "# shuffle\n",
    "dataset = dataset.shuffle(buffer_size)\n",
    "\n",
    "# form batch and epoch\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.repeat(num_epoch)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "# get a batch\n",
    "x_batch, y_batch = self.iterator.get_next()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write input pipeline to load batches as we train.\n",
    "The dataset is so large that it doesn't fit into memory. We have to load each batch as we're training.\n",
    "\n",
    "Plan (do this once for train and once for val):\n",
    "1. Store entire dataset as TFRecord.\n",
    "    - Convert each image to a TFExample as we're loading it from file. (Done)\n",
    "    - Store image in TFRecord of respecitve (train/val) dataset. (Done)\n",
    "2. Write custom generator which loads the batches from the TFRecord. \n",
    "    - https://medium.com/@mrgarg.rajat/training-on-large-datasets-that-dont-fit-in-memory-in-keras-60a974785d71\n",
    "3. Use custom generator with fit_generator.\n",
    "\n",
    "Implement performance speed-up: https://linuxtut.com/en/a7c31b08d2f76c886a92/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Generator\n",
    "Since dataset is too large to load it all into memory once, we need to load it from file in batches as we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Create a dictionary describing the features.\\nimage_feature_description = {\\n    'height': tf.io.FixedLenFeature([], tf.int64),\\n    'width': tf.io.FixedLenFeature([], tf.int64),\\n    'depth': tf.io.FixedLenFeature([], tf.int64),\\n    'label': tf.io.FixedLenFeature([], tf.int64),\\n    'image_raw': tf.io.FixedLenFeature([], tf.string),\\n}\\n\\ndef _parse_image_function(example_proto):\\n  # Parse the input tf.train.Example proto using the dictionary above.\\n  return tf.io.parse_single_example(example_proto, image_feature_description)\\n  \""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class TFRecords_Generator(tf.keras.utils.Sequence) :\\n  \\n    def __init__(self, record_filename, record_amount, batch_size) :\\n        self.record_filename = record_filename\\n        self.record_amount = record_amount\\n        self.batch_size = batch_size\\n\\n    def __len__(self) :\\n        return (np.ceil(self.record_amount / float(self.batch_size))).astype(int)\\n  \\n    def __getitem__(self, idx) :\\n        record_dataset = tf.data.TFRecordDataset(self.record_filename)\\n        parsed_image_records = record_dataset.map(_parse_image_function)\\n        \\n        ds2 = tf.data.TFRecordDataset(self.record_filename)           .batch(batch_size)           .apply(tf.data.experimental.parse_example_dataset(image_feature_description))           .map(dict2tuple)\\n\\n        #batch_records = \\n\\n        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\\n        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\\n\\n        return np.array([\\n                resize(imread('/content/all_images/' + str(file_name)), (80, 80, 3))\\n                   for file_name in batch_x])/255.0, np.array(batch_y)\\n                \""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class TFRecords_Generator(tf.keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, record_filename, record_amount, batch_size) :\n",
    "        self.record_filename = record_filename\n",
    "        self.record_amount = record_amount\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(self.record_amount / float(self.batch_size))).astype(int)\n",
    "  \n",
    "    def __getitem__(self, idx) :\n",
    "        record_dataset = tf.data.TFRecordDataset(self.record_filename)\n",
    "        parsed_image_records = record_dataset.map(_parse_image_function)\n",
    "        \n",
    "        ds2 = tf.data.TFRecordDataset(self.record_filename) \\\n",
    "          .batch(batch_size) \\\n",
    "          .apply(tf.data.experimental.parse_example_dataset(image_feature_description)) \\\n",
    "          .map(dict2tuple)\n",
    "\n",
    "        #batch_records = \n",
    "\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        return np.array([\n",
    "                resize(imread('/content/all_images/' + str(file_name)), (80, 80, 3))\n",
    "                   for file_name in batch_x])/255.0, np.array(batch_y)\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Raw_Generator(tf.keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, obs_ids, labels, batch_size) :\n",
    "        self.obs_ids = obs_ids\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.obs_ids) / float(self.batch_size))).astype(int)\n",
    "  \n",
    "    def __getitem__(self, idx) :\n",
    "        X_batch = list()\n",
    "        y_batch = list()\n",
    "\n",
    "        for i in range(idx * self.batch_size, (idx+1) * self.batch_size):\n",
    "            patch = load_patch(self.obs_ids[i], DATA_PATH, data='rgb')\n",
    "            X_batch.append(patch[0])\n",
    "            y_batch.append(self.labels[i])\n",
    "\n",
    "        return np.asarray(X_batch), np.array(y_batch)\n",
    "    \n",
    "    def generate_data(self):\n",
    "        for i in range(len(self.obs_ids)):\n",
    "            patch = load_patch(self.obs_ids[i], DATA_PATH, data='rgb')\n",
    "            x = tf.convert_to_tensor(patch[0])\n",
    "            y = self.labels[i]\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(tf.convert_to_tensor(load_patch(obs_id_train[0], DATA_PATH, data='rgb')[0], dtype=tf.Tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Simple Neural Network\n",
    "Let's create a first neural network as a baseline to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "# for distributed training\n",
    "# https://www.tensorflow.org/guide/distributed_training#use_tfdistributestrategy_with_keras_modelfit\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a 10 layer ReLU model of width 2\n",
    "def simple_model(input_shape):\n",
    "    \n",
    "    # for distributed training\n",
    "    with mirrored_strategy.scope():\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(Conv2D(6, 5, activation='tanh', input_shape=input_shape))\n",
    "        model.add(AveragePooling2D(2))\n",
    "        model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "        model.add(Conv2D(16, 5, activation='tanh'))\n",
    "        model.add(AveragePooling2D(2))\n",
    "        model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "        model.add(Conv2D(120, 5, activation='tanh'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(84, activation='tanh'))\n",
    "        model.add(Dense(17031, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    \"\"\"model = tf.keras.models.Sequential()\n",
    "    \n",
    "    # 1. Preprocessing\n",
    "    # rescale inputs\n",
    "    model.add(tf.keras.layers.Rescaling(1./255))\n",
    "    \n",
    "    # 2. Convolutional Layers\n",
    "    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(AveragePooling2D())\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(AveragePooling2D())\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(AveragePooling2D())\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, kernel_size=3, activation='relu', padding='same'))\n",
    "    \n",
    "    # from convolutional layers to dense layers\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    # 3. Dense Layers\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    # 4. Output Layer\n",
    "    model.add(Dense(17038, activation='softmax'))\"\"\"\n",
    "    \n",
    "    # compire the model\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "# create the network\n",
    "model = simple_model((256, 256, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelize I/O Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 256\n",
    "PRE_FETCH_NUM_BATCHES = 128\n",
    "NUM_THREADS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "To specify the output signature you need to provide either the `output_signature` argument or the `output_types` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m rawGen \u001b[38;5;241m=\u001b[39m Raw_Generator(obs_id_train, y_train, BATCHSIZE)\n\u001b[0;32m----> 2\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrawGen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x,y : (x,y), num_parallel_calls\u001b[38;5;241m=\u001b[39mNUM_THREADS)\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mPRE_FETCH_NUM_BATCHES)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#train_ds = dataset.batch(BATCHSIZE)\"\u001b[39;00m\n",
      "File \u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:548\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    541\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    542\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    543\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    547\u001b[0m           instructions)\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py:935\u001b[0m, in \u001b[0;36mDatasetV2.from_generator\u001b[0;34m(generator, output_types, output_shapes, args, output_signature, name)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m output_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo specify the output signature you need to provide \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither the `output_signature` argument or the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`output_types` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m output_shapes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: To specify the output signature you need to provide either the `output_signature` argument or the `output_types` argument."
     ]
    }
   ],
   "source": [
    "rawGen = Raw_Generator(obs_id_train, y_train, BATCHSIZE)\n",
    "train_ds = tf.data.Dataset.from_generator(rawGen.generate_data, output_types=(, np.int64), )\n",
    "train_ds = dataset.map(lambda x,y : (x,y), num_parallel_calls=NUM_THREADS).prefetch(buffer_size=PRE_FETCH_NUM_BATCHES)\n",
    "#train_ds = dataset.batch(BATCHSIZE)\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0.001, patience=5, \n",
    "                                              verbose=0, mode='auto', baseline=None, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Raw_Generator(obs_id_train, y_train, BATCHSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      " 509/6201 [=>............................] - ETA: 37:12 - loss: nan - accuracy: 0.0029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-121:\n",
      "Process Keras_worker_ForkPoolWorker-24:\n",
      "Process Keras_worker_ForkPoolWorker-73:\n",
      "Process Keras_worker_ForkPoolWorker-76:\n",
      "Process Keras_worker_ForkPoolWorker-108:\n",
      "Process Keras_worker_ForkPoolWorker-49:\n",
      "Process Keras_worker_ForkPoolWorker-23:\n",
      "Process Keras_worker_ForkPoolWorker-57:\n",
      "Process Keras_worker_ForkPoolWorker-2:\n",
      "Process Keras_worker_ForkPoolWorker-96:\n",
      "Process Keras_worker_ForkPoolWorker-56:\n",
      "Process Keras_worker_ForkPoolWorker-89:\n",
      "Process Keras_worker_ForkPoolWorker-35:\n",
      "Process Keras_worker_ForkPoolWorker-85:\n",
      "Process Keras_worker_ForkPoolWorker-67:\n",
      "Process Keras_worker_ForkPoolWorker-11:\n",
      "Process Keras_worker_ForkPoolWorker-42:\n",
      "Process Keras_worker_ForkPoolWorker-28:\n",
      "Process Keras_worker_ForkPoolWorker-81:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-55:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-43:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-46:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-50:\n",
      "Process Keras_worker_ForkPoolWorker-16:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-66:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-118:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-30:\n",
      "Process Keras_worker_ForkPoolWorker-1:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-80:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-114:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-21:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-75:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "Process Keras_worker_ForkPoolWorker-70:\n",
      "Process Keras_worker_ForkPoolWorker-106:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-13:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-48:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-128:\n",
      "Process Keras_worker_ForkPoolWorker-101:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Keras_worker_ForkPoolWorker-18:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Keras_worker_ForkPoolWorker-126:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Keras_worker_ForkPoolWorker-95:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Keras_worker_ForkPoolWorker-52:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "Process Keras_worker_ForkPoolWorker-58:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 131, in worker\n",
      "    put((job, i, result))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-116:\n",
      "Process Keras_worker_ForkPoolWorker-25:\n",
      "Process Keras_worker_ForkPoolWorker-65:\n",
      "Process Keras_worker_ForkPoolWorker-39:\n",
      "Process Keras_worker_ForkPoolWorker-111:\n",
      "Process Keras_worker_ForkPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-61:\n",
      "Process Keras_worker_ForkPoolWorker-91:\n",
      "Process Keras_worker_ForkPoolWorker-22:\n",
      "Process Keras_worker_ForkPoolWorker-123:\n",
      "Process Keras_worker_ForkPoolWorker-9:\n",
      "Process Keras_worker_ForkPoolWorker-127:\n",
      "Process Keras_worker_ForkPoolWorker-41:\n",
      "Process Keras_worker_ForkPoolWorker-60:\n",
      "Process Keras_worker_ForkPoolWorker-14:\n",
      "Process Keras_worker_ForkPoolWorker-82:\n",
      "Process Keras_worker_ForkPoolWorker-122:\n",
      "Process Keras_worker_ForkPoolWorker-8:\n",
      "Process Keras_worker_ForkPoolWorker-92:\n",
      "Process Keras_worker_ForkPoolWorker-87:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "Process Keras_worker_ForkPoolWorker-44:\n",
      "Process Keras_worker_ForkPoolWorker-78:\n",
      "Process Keras_worker_ForkPoolWorker-110:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "Process Keras_worker_ForkPoolWorker-125:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "Process Keras_worker_ForkPoolWorker-53:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-84:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-15:\n",
      "Process Keras_worker_ForkPoolWorker-72:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-26:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "Process Keras_worker_ForkPoolWorker-63:\n",
      "Process Keras_worker_ForkPoolWorker-117:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Process Keras_worker_ForkPoolWorker-7:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "Process Keras_worker_ForkPoolWorker-113:\n",
      "Process Keras_worker_ForkPoolWorker-33:\n",
      "Process Keras_worker_ForkPoolWorker-115:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-59:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 367, in put\n",
      "    with self._wlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-32:\n",
      "Process Keras_worker_ForkPoolWorker-105:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-36:\n",
      "Process Keras_worker_ForkPoolWorker-98:\n",
      "Process Keras_worker_ForkPoolWorker-64:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-90:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-99:\n",
      "Process Keras_worker_ForkPoolWorker-109:\n",
      "Process Keras_worker_ForkPoolWorker-40:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-88:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "Process Keras_worker_ForkPoolWorker-119:\n",
      "Process Keras_worker_ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-10:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-45:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-27:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-71:\n",
      "Process Keras_worker_ForkPoolWorker-31:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-77:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Keras_worker_ForkPoolWorker-120:\n",
      "Process Keras_worker_ForkPoolWorker-94:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-74:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Process Keras_worker_ForkPoolWorker-38:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-112:\n",
      "Process Keras_worker_ForkPoolWorker-54:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-34:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Process Keras_worker_ForkPoolWorker-102:\n",
      "Process Keras_worker_ForkPoolWorker-107:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-124:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-104:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Process Keras_worker_ForkPoolWorker-86:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-17:\n",
      "Process Keras_worker_ForkPoolWorker-12:\n",
      "Process Keras_worker_ForkPoolWorker-51:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Process Keras_worker_ForkPoolWorker-103:\n",
      "Process Keras_worker_ForkPoolWorker-37:\n",
      "Process Keras_worker_ForkPoolWorker-93:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-83:\n",
      "Process Keras_worker_ForkPoolWorker-47:\n",
      "Process Keras_worker_ForkPoolWorker-97:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Keras_worker_ForkPoolWorker-100:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "Process Keras_worker_ForkPoolWorker-79:\n",
      "Process Keras_worker_ForkPoolWorker-62:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Keras_worker_ForkPoolWorker-29:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 64, in load_patch\n",
      "    rgb_patch = np.asarray(rgb_patch)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 131, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 131, in worker\n",
      "    put((job, i, result))\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 362, in put\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 64, in load_patch\n",
      "    rgb_patch = np.asarray(rgb_patch)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 131, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 368, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 71, in load_patch\n",
      "    near_ir_patch = np.asarray(near_ir_patch)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 64, in load_patch\n",
      "    rgb_patch = np.asarray(rgb_patch)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 71, in load_patch\n",
      "    near_ir_patch = np.asarray(near_ir_patch)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3405, in __init__\n",
      "    if self.is_lsm and (\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 362, in put\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "KeyboardInterrupt\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 71, in load_patch\n",
      "    near_ir_patch = np.asarray(near_ir_patch)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3403, in __init__\n",
      "    self.pages = TiffPages(self)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 71, in load_patch\n",
      "    near_ir_patch = np.asarray(near_ir_patch)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 5261, in __getattr__\n",
      "    if name[3:] in TIFF.FILE_FLAGS:\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 405, in _send_bytes\n",
      "    self._send(buf)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 64, in load_patch\n",
      "    rgb_patch = np.asarray(rgb_patch)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 71, in load_patch\n",
      "    near_ir_patch = np.asarray(near_ir_patch)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 71, in load_patch\n",
      "    near_ir_patch = np.asarray(near_ir_patch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 64, in load_patch\n",
      "    rgb_patch = np.asarray(rgb_patch)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 71, in load_patch\n",
      "    near_ir_patch = np.asarray(near_ir_patch)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "KeyboardInterrupt\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 5803, in __init__\n",
      "    page = TiffPage(self.parent, index=pageindex)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 64, in load_patch\n",
      "    rgb_patch = np.asarray(rgb_patch)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 14692, in FILE_FLAGS\n",
      "    for a in dir(TiffPage)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "KeyboardInterrupt\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 64, in load_patch\n",
      "    rgb_patch = np.asarray(rgb_patch)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "KeyboardInterrupt\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "KeyboardInterrupt\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 6380, in __init__\n",
      "    tag = TiffTag.fromfile(\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3412, in __init__\n",
      "    elif self.is_scanimage and not self.is_bigtiff:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 8727, in fromfile\n",
      "    tiff = parent.tiff\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 5261, in __getattr__\n",
      "    if name[3:] in TIFF.FILE_FLAGS:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 14690, in FILE_FLAGS\n",
      "    return {\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 14690, in <setcomp>\n",
      "    return {\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "Process Keras_worker_ForkPoolWorker-4:\n",
      "Process Keras_worker_ForkPoolWorker-5:\n",
      "Process Keras_worker_ForkPoolWorker-68:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-69:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 71, in load_patch\n",
      "    near_ir_patch = np.asarray(near_ir_patch)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 71, in load_patch\n",
      "    near_ir_patch = np.asarray(near_ir_patch)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 675, in __array__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 718, in tobytes\n",
      "    self.load()\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/JpegImagePlugin.py\", line 402, in load_read\n",
      "    s = self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 81, in load_patch\n",
      "    landcover_patch = tifffile.imread(landcover_filename)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 69, in load_patch\n",
      "    near_ir_patch = Image.open(near_ir_filename)\n",
      "KeyboardInterrupt\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 62, in load_patch\n",
      "    rgb_patch = Image.open(rgb_filename)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-35-fe73ce5f43db>\", line 16, in __getitem__\n",
      "    patch = load_patch(self.obs_ids[i], DATA_PATH)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 2962, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/tf/dig/species-presence-prediction/GLC/data_loading/common.py\", line 76, in load_patch\n",
      "    altitude_patch = tifffile.imread(altitude_filename)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 900, in imread\n",
      "    with TiffFile(files, **kwargs_file) as tif:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 3357, in __init__\n",
      "    header = fh.read(4)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py\", line 11638, in read\n",
      "    return self._fh.read(size)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(generator, epochs=1, callbacks=[early_stop],\n",
    "#history = model.fit(train_ds, epochs=100, callbacks=[early_stop],\n",
    "                    max_queue_size=PRE_FETCH_NUM_BATCHES, workers=NUM_THREADS, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('first_simple_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
