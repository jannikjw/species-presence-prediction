{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GLC'...\n",
      "remote: Enumerating objects: 383, done.\u001b[K\n",
      "remote: Counting objects: 100% (228/228), done.\u001b[K\n",
      "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
      "remote: Total 383 (delta 119), reused 170 (delta 63), pack-reused 155\u001b[K\n",
      "Receiving objects: 100% (383/383), 10.57 MiB | 35.72 MiB/s, done.\n",
      "Resolving deltas: 100% (205/205), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf GLC\n",
    "!git clone https://github.com/maximiliense/GLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-ndsizsak because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Add, GlobalAveragePooling2D, Conv2D, Dense, AveragePooling2D, \\\n",
    "BatchNormalization, Normalization, Dropout, Flatten, Lambda, Input, Activation, MaxPooling2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import schedules, SGD\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import backend as K\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import scale\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import copy\n",
    "import threading\n",
    "import opendatasets as od\n",
    "\n",
    "%pylab inline --no-import-all\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from GLC.data_loading.common import load_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\"username\":\"nathaliemh\",\"key\":\"cba80d1f619e96b238e4a95aa3017836\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data = od.download(\"https://www.kaggle.com/competitions/geolifeclef-2022-lifeclef-2022-fgvc9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this path to adapt to where you downloaded the data\n",
    "DATA_PATH = Path(\"./geolifeclef-2022-lifeclef-2022-fgvc9/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmetadata\u001b[0m/      \u001b[01;34mpatches-fr\u001b[0m/  \u001b[01;34mpatches_sample\u001b[0m/  \u001b[01;34mrasters\u001b[0m/\r\n",
      "\u001b[01;34mobservations\u001b[0m/  \u001b[01;34mpatches-us\u001b[0m/  \u001b[01;34mpre-extracted\u001b[0m/   sample_submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls -L $DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observations_fr_test.csv   observations_us_test.csv\r\n",
      "observations_fr_train.csv  observations_us_train.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls $DATA_PATH/observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for training: 1627475\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>species_id</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10561949</th>\n",
       "      <td>45.705116</td>\n",
       "      <td>1.424622</td>\n",
       "      <td>241</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10131188</th>\n",
       "      <td>45.146973</td>\n",
       "      <td>6.416794</td>\n",
       "      <td>101</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799362</th>\n",
       "      <td>46.783695</td>\n",
       "      <td>-2.072855</td>\n",
       "      <td>700</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10392536</th>\n",
       "      <td>48.604866</td>\n",
       "      <td>-2.825003</td>\n",
       "      <td>1456</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10335049</th>\n",
       "      <td>48.815567</td>\n",
       "      <td>-0.161431</td>\n",
       "      <td>157</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 latitude  longitude  species_id subset\n",
       "observation_id                                         \n",
       "10561949        45.705116   1.424622         241  train\n",
       "10131188        45.146973   6.416794         101  train\n",
       "10799362        46.783695  -2.072855         700  train\n",
       "10392536        48.604866  -2.825003        1456  train\n",
       "10335049        48.815567  -0.161431         157  train"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Training Dataset ###\n",
    "# let's load the data from file\n",
    "df_obs_fr = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "\n",
    "df_obs = pd.concat((df_obs_fr, df_obs_us))\n",
    "\n",
    "print(\"Number of observations for training: {}\".format(len(df_obs)))\n",
    "\n",
    "# let's have a look at the data\n",
    "df_obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for testing: 36421\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10782781</th>\n",
       "      <td>43.601788</td>\n",
       "      <td>6.940195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10364138</th>\n",
       "      <td>46.241711</td>\n",
       "      <td>0.683586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10692017</th>\n",
       "      <td>45.181095</td>\n",
       "      <td>1.533459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10222322</th>\n",
       "      <td>46.938450</td>\n",
       "      <td>5.298678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10241950</th>\n",
       "      <td>45.017433</td>\n",
       "      <td>0.960736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 latitude  longitude\n",
       "observation_id                      \n",
       "10782781        43.601788   6.940195\n",
       "10364138        46.241711   0.683586\n",
       "10692017        45.181095   1.533459\n",
       "10222322        46.938450   5.298678\n",
       "10241950        45.017433   0.960736"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test Dataset ###\n",
    "df_obs_fr_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "\n",
    "df_obs_test = pd.concat((df_obs_fr_test, df_obs_us_test))\n",
    "\n",
    "print(\"Number of observations for testing: {}\".format(len(df_obs_test)))\n",
    "\n",
    "df_obs_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   landcover_code  suggested_landcover_code suggested_landcover_label\n",
      "0               0                         0              Missing Data\n",
      "1               1                        11          Cultivated Crops\n",
      "2               2                        11          Cultivated Crops\n",
      "3               3                         6       Broad-leaved Forest\n",
      "4               4                         7         Coniferous Forest\n"
     ]
    }
   ],
   "source": [
    "df_suggested_landcover_alignment = pd.read_csv(DATA_PATH / \"metadata\" / \"landcover_suggested_alignment.csv\", sep=\";\")\n",
    "print(df_suggested_landcover_alignment.head())\n",
    "landcover_mapping = df_suggested_landcover_alignment[\"suggested_landcover_code\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val Split Labels\n",
    "Retrieve the train/val split provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1587395 (97.5% of train observations)\n",
      "Validation set size: 40080 (2.5% of train observations)\n"
     ]
    }
   ],
   "source": [
    "obs_id_train = df_obs.index[df_obs[\"subset\"] == \"train\"].values\n",
    "obs_id_val = df_obs.index[df_obs[\"subset\"] == \"val\"].values\n",
    "\n",
    "#obs_id_train = obs_id_train[:int(len(obs_id_train)/3)]\n",
    "\n",
    "y_train = df_obs.loc[obs_id_train][\"species_id\"].values\n",
    "y_val = df_obs.loc[obs_id_val][\"species_id\"].values\n",
    "\n",
    "n_val = len(obs_id_val)\n",
    "print(\"Training set size: {} ({:.1%} of train observations)\".format(len(y_train), len(y_train) / len(df_obs)))\n",
    "print(\"Validation set size: {} ({:.1%} of train observations)\".format(n_val, n_val / len(df_obs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1587395\n"
     ]
    }
   ],
   "source": [
    "print(len(obs_id_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obs_id_train[int(1587395*0.99986):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17031"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# load training dataset samples\\n# factor = 1 means load full training dataset\\n# factor = 100 means load 1/100 of the full dataset\\nfactor = 1\\nlast_print = time.time()\\n\\n#X_train = list() #np.array((np.shape(y_train), 256, 256, 3))\\nX_train = np.zeros((len(obs_id_train), 256, 256, 3))\\nfor i in range(len(obs_id_train)):\\n    obs_id = obs_id_train[i]\\n    \\n    patch = load_patch(obs_id, DATA_PATH, landcover_mapping=landcover_mapping, data=\\'rgb\\')\\n    #X_train.append(patch[0])\\n    X_train[i] = patch[0]\\n    \\n    #percent_progress = len(X_train)/(len(y_train)/factor) * 100\\n    percent_progress = i/(len(y_train)/factor) * 100\\n    \\n    if time.time() - last_print > 1:\\n        sys.stdout.write(\\'\\r\\')\\n        # the exact output you\\'re looking for:\\n        sys.stdout.write(\"[%-20s] %.3f%%\" % (\\'=\\'*int(percent_progress/5), percent_progress))\\n        sys.stdout.flush()\\n        last_print = time.time()\\n        \\n    #if len(X_train) >= (len(y_train)/factor):\\n    #if percent_progress >= 99.98:\\n    #    break\\nprint(\"done with loading\")\\n    \\nX_train = np.array(X_train)\\nprint(\"sample array shape: \", np.shape(X_train))\\nprint(\"label array shape: \", np.shape(y_train))\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# load training dataset samples\n",
    "# factor = 1 means load full training dataset\n",
    "# factor = 100 means load 1/100 of the full dataset\n",
    "factor = 1\n",
    "last_print = time.time()\n",
    "\n",
    "#X_train = list() #np.array((np.shape(y_train), 256, 256, 3))\n",
    "X_train = np.zeros((len(obs_id_train), 256, 256, 3))\n",
    "for i in range(len(obs_id_train)):\n",
    "    obs_id = obs_id_train[i]\n",
    "    \n",
    "    patch = load_patch(obs_id, DATA_PATH, landcover_mapping=landcover_mapping, data='rgb')\n",
    "    #X_train.append(patch[0])\n",
    "    X_train[i] = patch[0]\n",
    "    \n",
    "    #percent_progress = len(X_train)/(len(y_train)/factor) * 100\n",
    "    percent_progress = i/(len(y_train)/factor) * 100\n",
    "    \n",
    "    if time.time() - last_print > 1:\n",
    "        sys.stdout.write('\\r')\n",
    "        # the exact output you're looking for:\n",
    "        sys.stdout.write(\"[%-20s] %.3f%%\" % ('='*int(percent_progress/5), percent_progress))\n",
    "        sys.stdout.flush()\n",
    "        last_print = time.time()\n",
    "        \n",
    "    #if len(X_train) >= (len(y_train)/factor):\n",
    "    #if percent_progress >= 99.98:\n",
    "    #    break\n",
    "print(\"done with loading\")\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "print(\"sample array shape: \", np.shape(X_train))\n",
    "print(\"label array shape: \", np.shape(y_train))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train[:]))\n",
    "#train_ds = train_ds.batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write patches and labels to TFRecord\n",
    "This only needs to be done once to obtain a TFRecord file. This file then can be reused during future runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.train.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def image_tfexample(img, label):\\n    image_shape = img.shape\\n\\n    feature = {\\n      'height': _int64_feature(image_shape[0]),\\n      'width': _int64_feature(image_shape[1]),\\n      'depth': _int64_feature(image_shape[2]),\\n      'label': _int64_feature(label),\\n      'image_raw': _bytes_feature(img.tobytes()),\\n    }\\n    \\n    return tf.train.Example(features=tf.train.Features(feature=feature))\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary with features that may be relevant.\n",
    "\"\"\"def image_tfexample(img, label):\n",
    "    image_shape = img.shape\n",
    "\n",
    "    feature = {\n",
    "      'height': _int64_feature(image_shape[0]),\n",
    "      'width': _int64_feature(image_shape[1]),\n",
    "      'depth': _int64_feature(image_shape[2]),\n",
    "      'label': _int64_feature(label),\n",
    "      'image_raw': _bytes_feature(img.tobytes()),\n",
    "    }\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def writeToTFRecord(obs_ids, labels, record_file):\\n    \\n    counter = 0\\n    last_print = time.time()\\n    \\n    options = tf.io.TFRecordOptions(compression_type = \\'GZIP\\')\\n    \\n    with tf.io.TFRecordWriter(record_file, options=options) as writer:\\n        for obs_id, label in zip(obs_ids, labels):\\n            patch = load_patch(obs_id, DATA_PATH)\\n\\n            # convert single rgb image + label to tf example\\n            tf_example = image_tfexample(patch[0], label)\\n\\n            # write to records file\\n            writer.write(tf_example.SerializeToString())\\n            counter += 1\\n\\n            if time.time() - last_print > 1:\\n                percent_progress = counter/len(labels) * 100\\n                sys.stdout.write(\\'\\r\\')\\n                sys.stdout.write(\"[%-20s] %.3f%%\" % (\\'=\\'*int(percent_progress/5), percent_progress))\\n                sys.stdout.flush()\\n                last_print = time.time()\\n                \\n            if counter > 10000:\\n                break\\n            \\n    return counter'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the raw image files to a TFRecord file (record_file).\n",
    "# First, process all images into `tf.train.Example` messages.\n",
    "# Then, write to a `.tfrecords` file.   \n",
    "\"\"\"def writeToTFRecord(obs_ids, labels, record_file):\n",
    "    \n",
    "    counter = 0\n",
    "    last_print = time.time()\n",
    "    \n",
    "    options = tf.io.TFRecordOptions(compression_type = 'GZIP')\n",
    "    \n",
    "    with tf.io.TFRecordWriter(record_file, options=options) as writer:\n",
    "        for obs_id, label in zip(obs_ids, labels):\n",
    "            patch = load_patch(obs_id, DATA_PATH)\n",
    "\n",
    "            # convert single rgb image + label to tf example\n",
    "            tf_example = image_tfexample(patch[0], label)\n",
    "\n",
    "            # write to records file\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "            counter += 1\n",
    "\n",
    "            if time.time() - last_print > 1:\n",
    "                percent_progress = counter/len(labels) * 100\n",
    "                sys.stdout.write('\\r')\n",
    "                sys.stdout.write(\"[%-20s] %.3f%%\" % ('='*int(percent_progress/5), percent_progress))\n",
    "                sys.stdout.flush()\n",
    "                last_print = time.time()\n",
    "                \n",
    "            if counter > 10000:\n",
    "                break\n",
    "            \n",
    "    return counter\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether it has the same length as y_train\n",
    "#np.shape(obs_id_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write training dataset samples to TFrecord\n",
    "#train_record_amount = writeToTFRecord(obs_id_train, y_train, record_file = 'training.tfrecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write training dataset samples to TFrecord\n",
    "#val_record_amount = writeToTFRecord(obs_id_val, y_val, record_file = 'validation.tfrecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing Around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to TFRecords file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def image_tfexample(img, label):\\n    image_shape = img.shape\\n\\n    feature = {\\n      'height': _int64_feature(image_shape[0]),\\n      'width': _int64_feature(image_shape[1]),\\n      'depth': _int64_feature(image_shape[2]),\\n      'label': _int64_feature(label),\\n      'image_raw': _bytes_feature(img),\\n    }\\n    \\n    return tf.train.Example(features=tf.train.Features(feature=feature))\\n    \""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary with features that may be relevant.\n",
    "\"\"\"def image_tfexample(img, label):\n",
    "    image_shape = img.shape\n",
    "\n",
    "    feature = {\n",
    "      'height': _int64_feature(image_shape[0]),\n",
    "      'width': _int64_feature(image_shape[1]),\n",
    "      'depth': _int64_feature(image_shape[2]),\n",
    "      'label': _int64_feature(label),\n",
    "      'image_raw': _bytes_feature(img),\n",
    "    }\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"record_file = 'X_train.tfrecords'\\nwith tf.io.TFRecordWriter(record_file) as writer:\\n    for img, label in zip(X_train, y_train):\\n\\n        # convert single image + label to tf example\\n        img_string = np.array2string(img)\\n        tf_example = image_tfexample(img, label)\\n    \\n        # write to records file\\n        writer.write(tf_example.SerializeToString())\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the raw image files to `images.tfrecords`.\n",
    "# First, process all images into `tf.train.Example` messages.\n",
    "# Then, write to a `.tfrecords` file.\n",
    "\n",
    "\"\"\"record_file = 'X_train.tfrecords'\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    for img, label in zip(X_train, y_train):\n",
    "\n",
    "        # convert single image + label to tf example\n",
    "        img_string = np.array2string(img)\n",
    "        tf_example = image_tfexample(img, label)\n",
    "    \n",
    "        # write to records file\n",
    "        writer.write(tf_example.SerializeToString())\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read first few images from records file to ensure it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"image_feature_description = {\\n    'height': tf.io.FixedLenFeature([], tf.int64),\\n    'width': tf.io.FixedLenFeature([], tf.int64),\\n    'depth': tf.io.FixedLenFeature([], tf.int64),\\n    'label': tf.io.FixedLenFeature([], tf.int64),\\n    'image_raw': tf.io.FixedLenFeature([], tf.string),\\n}\\n\\ndef _parse_image_function(example_proto):\\n  # Parse the input tf.train.Example proto using the dictionary above.\\n  return tf.io.parse_single_example(example_proto, image_feature_description)\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary describing the features.\n",
    "\"\"\"image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image_records = tf.data.TFRecordDataset(record_file)\\nparsed_image_records = image_records.map(_parse_image_function)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"image_records = tf.data.TFRecordDataset(record_file)\n",
    "parsed_image_records = image_records.map(_parse_image_function)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for record in parsed_image_records:\\n  image_raw = record['image_raw'].numpy()\\n  display.display(display.Image(data=image_raw))\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for record in parsed_image_records:\n",
    "  image_raw = record['image_raw'].numpy()\n",
    "  display.display(display.Image(data=image_raw))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load entire dataset in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# read file\\ndataset = tf.data.TFRecordDataset(record_file)\\n\\n# parse each instance\\ndataset = dataset.map(_parse_image_function, num_parallel_calls=num_threads)\\n\\n# shuffle\\ndataset = dataset.shuffle(buffer_size)\\n\\n# form batch and epoch\\ndataset = dataset.batch(batch_size)\\ndataset = dataset.repeat(num_epoch)\\niterator = dataset.make_one_shot_iterator()\\n\\n# get a batch\\nx_batch, y_batch = self.iterator.get_next()\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# read file\n",
    "dataset = tf.data.TFRecordDataset(record_file)\n",
    "\n",
    "# parse each instance\n",
    "dataset = dataset.map(_parse_image_function, num_parallel_calls=num_threads)\n",
    "\n",
    "# shuffle\n",
    "dataset = dataset.shuffle(buffer_size)\n",
    "\n",
    "# form batch and epoch\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.repeat(num_epoch)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "# get a batch\n",
    "x_batch, y_batch = self.iterator.get_next()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write input pipeline to load batches as we train.\n",
    "The dataset is so large that it doesn't fit into memory. We have to load each batch as we're training.\n",
    "\n",
    "Plan (do this once for train and once for val):\n",
    "1. Store entire dataset as TFRecord.\n",
    "    - Convert each image to a TFExample as we're loading it from file. (Done)\n",
    "    - Store image in TFRecord of respecitve (train/val) dataset. (Done)\n",
    "2. Write custom generator which loads the batches from the TFRecord. \n",
    "    - https://medium.com/@mrgarg.rajat/training-on-large-datasets-that-dont-fit-in-memory-in-keras-60a974785d71\n",
    "3. Use custom generator with fit_generator.\n",
    "\n",
    "Implement performance speed-up: https://linuxtut.com/en/a7c31b08d2f76c886a92/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Generator\n",
    "Since dataset is too large to load it all into memory once, we need to load it from file in batches as we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Create a dictionary describing the features.\\nimage_feature_description = {\\n    'height': tf.io.FixedLenFeature([], tf.int64),\\n    'width': tf.io.FixedLenFeature([], tf.int64),\\n    'depth': tf.io.FixedLenFeature([], tf.int64),\\n    'label': tf.io.FixedLenFeature([], tf.int64),\\n    'image_raw': tf.io.FixedLenFeature([], tf.string),\\n}\\n\\ndef _parse_image_function(example_proto):\\n  # Parse the input tf.train.Example proto using the dictionary above.\\n  return tf.io.parse_single_example(example_proto, image_feature_description)\\n  \""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class TFRecords_Generator(tf.keras.utils.Sequence) :\\n  \\n    def __init__(self, record_filename, record_amount, batch_size) :\\n        self.record_filename = record_filename\\n        self.record_amount = record_amount\\n        self.batch_size = batch_size\\n\\n    def __len__(self) :\\n        return (np.ceil(self.record_amount / float(self.batch_size))).astype(int)\\n  \\n    def __getitem__(self, idx) :\\n        record_dataset = tf.data.TFRecordDataset(self.record_filename)\\n        parsed_image_records = record_dataset.map(_parse_image_function)\\n        \\n        ds2 = tf.data.TFRecordDataset(self.record_filename)           .batch(batch_size)           .apply(tf.data.experimental.parse_example_dataset(image_feature_description))           .map(dict2tuple)\\n\\n        #batch_records = \\n\\n        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\\n        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\\n\\n        return np.array([\\n                resize(imread('/content/all_images/' + str(file_name)), (80, 80, 3))\\n                   for file_name in batch_x])/255.0, np.array(batch_y)\\n                \""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class TFRecords_Generator(tf.keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, record_filename, record_amount, batch_size) :\n",
    "        self.record_filename = record_filename\n",
    "        self.record_amount = record_amount\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(self.record_amount / float(self.batch_size))).astype(int)\n",
    "  \n",
    "    def __getitem__(self, idx) :\n",
    "        record_dataset = tf.data.TFRecordDataset(self.record_filename)\n",
    "        parsed_image_records = record_dataset.map(_parse_image_function)\n",
    "        \n",
    "        ds2 = tf.data.TFRecordDataset(self.record_filename) \\\n",
    "          .batch(batch_size) \\\n",
    "          .apply(tf.data.experimental.parse_example_dataset(image_feature_description)) \\\n",
    "          .map(dict2tuple)\n",
    "\n",
    "        #batch_records = \n",
    "\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        return np.array([\n",
    "                resize(imread('/content/all_images/' + str(file_name)), (80, 80, 3))\n",
    "                   for file_name in batch_x])/255.0, np.array(batch_y)\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Raw_Generator(tf.keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, obs_ids, labels, batch_size) :\n",
    "        self.obs_ids = obs_ids\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.obs_ids) / float(self.batch_size))).astype(int)\n",
    "  \n",
    "    def __getitem__(self, idx) :\n",
    "        X_batch = list()\n",
    "        y_batch = list()\n",
    "\n",
    "        for i in range(idx * self.batch_size, (idx+1) * self.batch_size):\n",
    "            patch = load_patch(self.obs_ids[i], DATA_PATH, data='rgb')\n",
    "            X_batch.append(patch[0])\n",
    "            y_batch.append(self.labels[i])\n",
    "\n",
    "        with self.lock:\n",
    "            return np.asarray(X_batch), np.array(y_batch)\n",
    "    \n",
    "    def generate_data(self):\n",
    "        for i in range(len(self.obs_ids)):\n",
    "            patch = load_patch(self.obs_ids[i], DATA_PATH, data='rgb')\n",
    "            x = tf.convert_to_tensor(patch[0])\n",
    "            y = self.labels[i]\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Simple Neural Network\n",
    "Let's create a first neural network as a baseline to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "# for distributed training\n",
    "# https://www.tensorflow.org/guide/distributed_training#use_tfdistributestrategy_with_keras_modelfit\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a 10 layer ReLU model of width 2\n",
    "def simple_model(input_shape):\n",
    "    \n",
    "    # for distributed training\n",
    "    with mirrored_strategy.scope():\n",
    "        \"\"\"model = tf.keras.models.Sequential()\n",
    "        model.add(Conv2D(6, 5, activation='tanh', input_shape=input_shape))\n",
    "        model.add(AveragePooling2D(2))\n",
    "        model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "        model.add(Conv2D(16, 5, activation='tanh'))\n",
    "        model.add(AveragePooling2D(2))\n",
    "        model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "        model.add(Conv2D(120, 5, activation='tanh'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(84, activation='tanh'))\n",
    "        model.add(Dense(17031, activation='softmax'))\"\"\"\n",
    "    \n",
    "    \n",
    "        model = tf.keras.models.Sequential()\n",
    "\n",
    "        # 1. Preprocessing\n",
    "        # rescale inputs\n",
    "        model.add(tf.keras.layers.Rescaling(1./255))\n",
    "\n",
    "        # 2. Convolutional Layers\n",
    "        model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=input_shape, padding='valid'))\n",
    "        model.add(MaxPooling2D())\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=3, activation='relu', padding='valid'))\n",
    "        model.add(MaxPooling2D())\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size=3, activation='relu', padding='valid'))\n",
    "        model.add(MaxPooling2D())\n",
    "\n",
    "        model.add(Conv2D(256, kernel_size=3, activation='relu', padding='valid'))\n",
    "\n",
    "        # from convolutional layers to dense layers\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "        # 3. Dense Layers\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "\n",
    "        # 4. Output Layer\n",
    "        model.add(Dense(17038, activation='softmax'))\n",
    "    \n",
    "    # compire the model\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the network\n",
    "model = simple_model((256, 256, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelize I/O Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 512\n",
    "NUM_THREADS = 140\n",
    "PRE_FETCH_NUM_BATCHES = int(NUM_THREADS * 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"rawGen = Raw_Generator(obs_id_train, y_train, BATCHSIZE)\n",
    "train_ds = tf.data.Dataset.from_generator(rawGen.generate_data, output_types=(np.uint8, np.int64), )\n",
    "train_ds = train_ds.map(lambda x,y : (x,y), num_parallel_calls=NUM_THREADS).prefetch(buffer_size=PRE_FETCH_NUM_BATCHES)\n",
    "train_ds = train_ds.batch(BATCHSIZE)\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0.001, patience=5, \n",
    "                                              verbose=0, mode='auto', baseline=None, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Raw_Generator(obs_id_train, y_train, BATCHSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 12 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 12 all-reduces with algorithm = nccl, num_packs = 1\n",
      " 496/3100 [===>..........................] - ETA: 23:16 - loss: 12498.0322 - accuracy: 0.0040"
     ]
    }
   ],
   "source": [
    "history = model.fit(generator, epochs=100, steps_per_epoch=len(y_train)//BATCHSIZE, callbacks=[early_stop], \n",
    "#history = model.fit(train_ds, epochs=100, callbacks=[early_stop])\n",
    "                    max_queue_size=PRE_FETCH_NUM_BATCHES, workers=NUM_THREADS, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('first_simple_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
