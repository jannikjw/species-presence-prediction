{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf18b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab7ebbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15510/437406094.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/species-presence-prediction/utils/data_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./geolifeclef-2022-lifeclef-2022-fgvc9/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# let's load the data from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdf_obs_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"observations\"\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"observations_fr_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"observation_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "\n",
    "X_train = loader.subset_labels(num_labels=10, set_type='train')\n",
    "X_val = loader.subset_labels(num_labels=10, set_type='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f22612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_modal_cnn():\n",
    "    with mirrored_strategy.scope():\n",
    "\n",
    "        # Inputs\n",
    "        patch_input = layers.Input(shape=(256, 256, 6), dtype='float32')\n",
    "        tabular_input = layers.Input(shape=(29), dtype='float32')  \n",
    "\n",
    "        # Augment data\n",
    "    #     augmented = data_augmentation_for_visualization(patch_input)\n",
    "\n",
    "        # From Scratch model\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu')(patch_input)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(256, (3, 3), activation='relu')(x)\n",
    "        x = layers.MaxPooling2D((1, 1), padding='same')(x)\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), padding='same')(x)      \n",
    "\n",
    "        # Add Dense layers for images\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "        # Add Dense layers for Tabular data\n",
    "        y = layers.Dense(512, activation='relu')(tabular_input)\n",
    "        y = layers.Dense(256, activation='relu')(y)\n",
    "\n",
    "        # Concatenate Image and tabular weights\n",
    "        z = layers.Concatenate(axis=1)([x, y])\n",
    "\n",
    "        # Add Classification Head\n",
    "        z = layers.Dense(128, activation='relu')(z)\n",
    "        classifier = layers.Dense(NUM_CLASSES, name='outputs', activation='softmax')(z)\n",
    "\n",
    "        # Define inputs and outputs\n",
    "        model = tf.keras.Model(inputs=[patch_input, tabular_input], outputs=classifier)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tfa.optimizers.AdamW(learning_rate=LEARNING_RATE, \n",
    "                                         weight_decay=weight_decay_rate)\n",
    "        # Compile model\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=[\n",
    "                          tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "                          tf.keras.metrics.SparseTopKCategoricalAccuracy(10, name=\"top-10-accuracy\")\n",
    "                      ]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efb65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches_Generator_CNN(tf.keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, obs_ids, labels, batch_size) :\n",
    "        self.obs_ids = obs_ids\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # to make the generator thread safe \n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.floor(len(self.obs_ids) / float(self.batch_size))).astype(int)\n",
    "  \n",
    "    # returns one batch\n",
    "    def __getitem__(self, idx) :\n",
    "        X_batch = list()\n",
    "        X_env_batch = list()\n",
    "        y_batch = list()\n",
    "\n",
    "        for i in range(idx * self.batch_size, (idx+1) * self.batch_size):\n",
    "            if i >= len(self.obs_ids): break\n",
    "            \n",
    "            rgb, near_ir, landcover, altitude = load_patch(self.obs_ids[i], DATA_PATH)\n",
    "\n",
    "            ni = near_ir.reshape(256, 256, 1)\n",
    "            lc = landcover.reshape(256, 256, 1)\n",
    "            alt = altitude.reshape(256, 256, 1)\n",
    "\n",
    "            patch = np.concatenate((rgb, ni, lc, alt), axis=2)\n",
    "            \n",
    "            X_batch.append(patch)\n",
    "            y_batch.append(self.labels[i])\n",
    "            \n",
    "            X_env_batch.append(tabular_train.loc[self.obs_ids[i]].values)\n",
    "            \n",
    "        with self.lock:\n",
    "            return {'input_1': np.asarray(X_batch), 'input_2': np.asarray(X_env_batch)}, np.asarray(np.array(y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e72cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Patches_Generator_CNN(X_train_idx, y_train, BATCH_SIZE)\n",
    "val_data = Patches_Generator_CNN(X_val_idx, y_val, BATCH_SIZE)\n",
    "\n",
    "# converting our train dataset to tf.data.Dataset\n",
    "tf_train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_data ,  # Our generator \n",
    "    output_types = ({'input_1': tf.float32 , 'input_2': tf.float32}, tf.float32) , # How we're expecting our output dtype\n",
    "#     output_shapes = ({'input_1': [BATCH_SIZE, 256 , 256, 6], 'input_2': [BATCH_SIZE, 29]} , [BATCH_SIZE, ]) # How we're expecting our output shape\n",
    ")\n",
    "\n",
    "tf_val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: val_data , \n",
    "    output_types = ({'input_1': tf.float32 , 'input_2': tf.float32}, tf.float32),\n",
    "#     output_shapes = ({'input_1': [BATCH_SIZE, 256 , 256, 6], 'input_2': [BATCH_SIZE, 29]} , [BATCH_SIZE, ]) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6940d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_results = model.fit(\n",
    "    tf_train_dataset.repeat(),\n",
    "    steps_per_epoch=np.floor(len(y_train)/BATCH_SIZE)*4,\n",
    "    validation_data=tf_val_dataset.repeat(),\n",
    "    validation_steps=np.floor(len(y_val)/BATCH_SIZE)*4,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    max_queue_size=PRE_FETCH_NUM_BATCHES, \n",
    "    workers=NUM_THREADS, \n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b833994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
