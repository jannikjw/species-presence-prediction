{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXQtVUBd6wBb"
      },
      "source": [
        "### Necessary Imports and Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQgUSoTq6wBe",
        "outputId": "a8789c73-255f-4c6d-efbb-6d5ecc0e6fe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.62.3)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJkv9H5j6wBh",
        "outputId": "e1f6e908-0be5-4c80-b63f-2cfe8d5c8b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GLC'...\n",
            "remote: Enumerating objects: 383, done.\u001b[K\n",
            "remote: Counting objects: 100% (228/228), done.\u001b[K\n",
            "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
            "remote: Total 383 (delta 119), reused 170 (delta 63), pack-reused 155\u001b[K\n",
            "Receiving objects: 100% (383/383), 10.57 MiB | 42.27 MiB/s, done.\n",
            "Resolving deltas: 100% (205/205), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf GLC\n",
        "!git clone https://github.com/maximiliense/GLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttVuFo5z6wBk",
        "outputId": "8680d55a-1b18-4f48-ba40-1a860d452d4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Add, GlobalAveragePooling2D, Conv2D, Dense, AveragePooling2D, \\\n",
        "BatchNormalization, Normalization, Dropout, Flatten, Lambda, Input, Activation\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import schedules, SGD\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import scale\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import copy\n",
        "import opendatasets as od\n",
        "\n",
        "%pylab inline --no-import-all\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcvMxKoO6wBm"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQg6_lGN6wBm"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R09SwJjr6wBn"
      },
      "source": [
        "{\"username\":\"nathaliemh\",\"key\":\"cba80d1f619e96b238e4a95aa3017836\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN3ijYXC6wBn",
        "outputId": "c5b970c7-9f83-4c85-ee70-88c825b89c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: kennedysalamat\n",
            "Your Kaggle Key: ··········\n",
            "Downloading geolifeclef-2022-lifeclef-2022-fgvc9.zip to ./geolifeclef-2022-lifeclef-2022-fgvc9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57.6G/57.6G [07:09<00:00, 144MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting archive ./geolifeclef-2022-lifeclef-2022-fgvc9/geolifeclef-2022-lifeclef-2022-fgvc9.zip to ./geolifeclef-2022-lifeclef-2022-fgvc9\n"
          ]
        }
      ],
      "source": [
        "data = od.download(\"https://www.kaggle.com/competitions/geolifeclef-2022-lifeclef-2022-fgvc9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYkotg_W6wBo"
      },
      "source": [
        "## Load Dataset from file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0l13ymn6wBo"
      },
      "outputs": [],
      "source": [
        "# Change this path to adapt to where you downloaded the data\n",
        "DATA_PATH = \"./geolifeclef-2022-lifeclef-2022-fgvc9/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d92lNVZ-6wBp"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "hours = 4\n",
        "#time.sleep(60*60*hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay-ptsAe6wBq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06010ec4-5726-4390-dc8d-83917a4fba83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mmetadata\u001b[0m/      \u001b[01;34mpatches-fr\u001b[0m/      \u001b[01;34mpatches-us\u001b[0m/     \u001b[01;34mrasters\u001b[0m/\n",
            "\u001b[01;34mobservations\u001b[0m/  \u001b[01;34mpatches_sample\u001b[0m/  \u001b[01;34mpre-extracted\u001b[0m/  sample_submission.csv\n"
          ]
        }
      ],
      "source": [
        "ls -L $DATA_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMIdyChK6wBq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "033f700b-ae6d-4904-8d25-348f2bcc81e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "observations_fr_test.csv   observations_us_test.csv\n",
            "observations_fr_train.csv  observations_us_train.csv\n"
          ]
        }
      ],
      "source": [
        "ls $DATA_PATH/observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJJTCmd-6wBt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "856f737b-d731-40a8-e9f6-6e2aa0b1a2c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of observations for training: 1627475\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c711b2ff-b19f-4d13-bcbd-36ca5b2e8e5f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>species_id</th>\n",
              "      <th>subset</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>observation_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10561949</th>\n",
              "      <td>45.705116</td>\n",
              "      <td>1.424622</td>\n",
              "      <td>241</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10131188</th>\n",
              "      <td>45.146973</td>\n",
              "      <td>6.416794</td>\n",
              "      <td>101</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10799362</th>\n",
              "      <td>46.783695</td>\n",
              "      <td>-2.072855</td>\n",
              "      <td>700</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10392536</th>\n",
              "      <td>48.604866</td>\n",
              "      <td>-2.825003</td>\n",
              "      <td>1456</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10335049</th>\n",
              "      <td>48.815567</td>\n",
              "      <td>-0.161431</td>\n",
              "      <td>157</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c711b2ff-b19f-4d13-bcbd-36ca5b2e8e5f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c711b2ff-b19f-4d13-bcbd-36ca5b2e8e5f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c711b2ff-b19f-4d13-bcbd-36ca5b2e8e5f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 latitude  longitude  species_id subset\n",
              "observation_id                                         \n",
              "10561949        45.705116   1.424622         241  train\n",
              "10131188        45.146973   6.416794         101  train\n",
              "10799362        46.783695  -2.072855         700  train\n",
              "10392536        48.604866  -2.825003        1456  train\n",
              "10335049        48.815567  -0.161431         157  train"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "### Training Dataset ###\n",
        "# let's load the data from file\n",
        "df_obs_fr = pd.read_csv(DATA_PATH + \"/observations/observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
        "df_obs_us = pd.read_csv(DATA_PATH + \"/observations/observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
        "\n",
        "df_obs = pd.concat((df_obs_fr, df_obs_us))\n",
        "\n",
        "\n",
        "print(\"Number of observations for training: {}\".format(len(df_obs)))\n",
        "\n",
        "# let's have a look at the data\n",
        "df_obs.head()\n",
        "\n",
        "#print(x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3xCgPJi6wBu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "891c796e-0a22-444b-d5cd-18d0e4a97f1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of observations for testing: 36421\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6945001b-5c15-4d83-90de-a9646b837973\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>observation_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10782781</th>\n",
              "      <td>43.601788</td>\n",
              "      <td>6.940195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10364138</th>\n",
              "      <td>46.241711</td>\n",
              "      <td>0.683586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10692017</th>\n",
              "      <td>45.181095</td>\n",
              "      <td>1.533459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10222322</th>\n",
              "      <td>46.938450</td>\n",
              "      <td>5.298678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10241950</th>\n",
              "      <td>45.017433</td>\n",
              "      <td>0.960736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6945001b-5c15-4d83-90de-a9646b837973')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6945001b-5c15-4d83-90de-a9646b837973 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6945001b-5c15-4d83-90de-a9646b837973');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 latitude  longitude\n",
              "observation_id                      \n",
              "10782781        43.601788   6.940195\n",
              "10364138        46.241711   0.683586\n",
              "10692017        45.181095   1.533459\n",
              "10222322        46.938450   5.298678\n",
              "10241950        45.017433   0.960736"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "### Test Dataset ###\n",
        "df_obs_fr_test = pd.read_csv(DATA_PATH + \"/observations/observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
        "df_obs_us_test = pd.read_csv(DATA_PATH + \"/observations/observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
        "\n",
        "df_obs_test = pd.concat((df_obs_fr_test, df_obs_us_test))\n",
        "\n",
        "\n",
        "print(\"Number of observations for testing: {}\".format(len(df_obs_test)))\n",
        "\n",
        "df_obs_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BMxfMABtgja4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x24PvjPR6wBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c74cfe-5b93-4db6-f8fa-121c865b1874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m00\u001b[0m/  \u001b[01;34m07\u001b[0m/  \u001b[01;34m14\u001b[0m/  \u001b[01;34m21\u001b[0m/  \u001b[01;34m28\u001b[0m/  \u001b[01;34m35\u001b[0m/  \u001b[01;34m42\u001b[0m/  \u001b[01;34m49\u001b[0m/  \u001b[01;34m56\u001b[0m/  \u001b[01;34m63\u001b[0m/  \u001b[01;34m70\u001b[0m/  \u001b[01;34m77\u001b[0m/  \u001b[01;34m84\u001b[0m/  \u001b[01;34m91\u001b[0m/  \u001b[01;34m98\u001b[0m/\n",
            "\u001b[01;34m01\u001b[0m/  \u001b[01;34m08\u001b[0m/  \u001b[01;34m15\u001b[0m/  \u001b[01;34m22\u001b[0m/  \u001b[01;34m29\u001b[0m/  \u001b[01;34m36\u001b[0m/  \u001b[01;34m43\u001b[0m/  \u001b[01;34m50\u001b[0m/  \u001b[01;34m57\u001b[0m/  \u001b[01;34m64\u001b[0m/  \u001b[01;34m71\u001b[0m/  \u001b[01;34m78\u001b[0m/  \u001b[01;34m85\u001b[0m/  \u001b[01;34m92\u001b[0m/  \u001b[01;34m99\u001b[0m/\n",
            "\u001b[01;34m02\u001b[0m/  \u001b[01;34m09\u001b[0m/  \u001b[01;34m16\u001b[0m/  \u001b[01;34m23\u001b[0m/  \u001b[01;34m30\u001b[0m/  \u001b[01;34m37\u001b[0m/  \u001b[01;34m44\u001b[0m/  \u001b[01;34m51\u001b[0m/  \u001b[01;34m58\u001b[0m/  \u001b[01;34m65\u001b[0m/  \u001b[01;34m72\u001b[0m/  \u001b[01;34m79\u001b[0m/  \u001b[01;34m86\u001b[0m/  \u001b[01;34m93\u001b[0m/\n",
            "\u001b[01;34m03\u001b[0m/  \u001b[01;34m10\u001b[0m/  \u001b[01;34m17\u001b[0m/  \u001b[01;34m24\u001b[0m/  \u001b[01;34m31\u001b[0m/  \u001b[01;34m38\u001b[0m/  \u001b[01;34m45\u001b[0m/  \u001b[01;34m52\u001b[0m/  \u001b[01;34m59\u001b[0m/  \u001b[01;34m66\u001b[0m/  \u001b[01;34m73\u001b[0m/  \u001b[01;34m80\u001b[0m/  \u001b[01;34m87\u001b[0m/  \u001b[01;34m94\u001b[0m/\n",
            "\u001b[01;34m04\u001b[0m/  \u001b[01;34m11\u001b[0m/  \u001b[01;34m18\u001b[0m/  \u001b[01;34m25\u001b[0m/  \u001b[01;34m32\u001b[0m/  \u001b[01;34m39\u001b[0m/  \u001b[01;34m46\u001b[0m/  \u001b[01;34m53\u001b[0m/  \u001b[01;34m60\u001b[0m/  \u001b[01;34m67\u001b[0m/  \u001b[01;34m74\u001b[0m/  \u001b[01;34m81\u001b[0m/  \u001b[01;34m88\u001b[0m/  \u001b[01;34m95\u001b[0m/\n",
            "\u001b[01;34m05\u001b[0m/  \u001b[01;34m12\u001b[0m/  \u001b[01;34m19\u001b[0m/  \u001b[01;34m26\u001b[0m/  \u001b[01;34m33\u001b[0m/  \u001b[01;34m40\u001b[0m/  \u001b[01;34m47\u001b[0m/  \u001b[01;34m54\u001b[0m/  \u001b[01;34m61\u001b[0m/  \u001b[01;34m68\u001b[0m/  \u001b[01;34m75\u001b[0m/  \u001b[01;34m82\u001b[0m/  \u001b[01;34m89\u001b[0m/  \u001b[01;34m96\u001b[0m/\n",
            "\u001b[01;34m06\u001b[0m/  \u001b[01;34m13\u001b[0m/  \u001b[01;34m20\u001b[0m/  \u001b[01;34m27\u001b[0m/  \u001b[01;34m34\u001b[0m/  \u001b[01;34m41\u001b[0m/  \u001b[01;34m48\u001b[0m/  \u001b[01;34m55\u001b[0m/  \u001b[01;34m62\u001b[0m/  \u001b[01;34m69\u001b[0m/  \u001b[01;34m76\u001b[0m/  \u001b[01;34m83\u001b[0m/  \u001b[01;34m90\u001b[0m/  \u001b[01;34m97\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls $DATA_PATH/patches-fr/00"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKduRYbU6wBw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a14f1914-f482-49f8-b23d-02e9285f63a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9e6f15c1-352d-44d5-a439-5e97401e314a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>landcover_code</th>\n",
              "      <th>suggested_landcover_code</th>\n",
              "      <th>suggested_landcover_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Missing Data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>Cultivated Crops</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>Cultivated Crops</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Broad-leaved Forest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>Coniferous Forest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e6f15c1-352d-44d5-a439-5e97401e314a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e6f15c1-352d-44d5-a439-5e97401e314a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e6f15c1-352d-44d5-a439-5e97401e314a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   landcover_code  suggested_landcover_code suggested_landcover_label\n",
              "0               0                         0              Missing Data\n",
              "1               1                        11          Cultivated Crops\n",
              "2               2                        11          Cultivated Crops\n",
              "3               3                         6       Broad-leaved Forest\n",
              "4               4                         7         Coniferous Forest"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_suggested_landcover_alignment = pd.read_csv(DATA_PATH + \"/metadata/landcover_suggested_alignment.csv\", sep=\";\")\n",
        "df_suggested_landcover_alignment.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERfilO456wBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5246774-da9a-46e5-df49-4f2c055be4cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data sources: 4\n",
            "Arrays shape: [(256, 256, 3), (256, 256), (256, 256), (256, 256)]\n",
            "Data types: [dtype('uint8'), dtype('uint8'), dtype('int16'), dtype('uint8')]\n"
          ]
        }
      ],
      "source": [
        "from GLC.data_loading.common import load_patch\n",
        "\n",
        "patch = load_patch(10171444, DATA_PATH)\n",
        "\n",
        "print(\"Number of data sources: {}\".format(len(patch)))\n",
        "print(\"Arrays shape: {}\".format([p.shape for p in patch]))\n",
        "print(\"Data types: {}\".format([p.dtype for p in patch]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jo60DVwq6wBx"
      },
      "outputs": [],
      "source": [
        "landcover_mapping = df_suggested_landcover_alignment[\"suggested_landcover_code\"].values\n",
        "#patch = load_patch(10171444, DATA_PATH, landcover_mapping=landcover_mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "56Q_qdBu_iO5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFHeF5wH6wBy"
      },
      "source": [
        "### Train/Val Split Labels\n",
        "Retrieve the train/val split provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5p0CE3R6wBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a08104-f3ab-4f94-b3f9-107f0e8d9df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 1587395 (97.5% of train observations)\n",
            "Validation set size: 40080 (2.5% of train observations)\n"
          ]
        }
      ],
      "source": [
        "obs_id_train = df_obs.index[df_obs[\"subset\"] == \"train\"].values\n",
        "obs_id_val = df_obs.index[df_obs[\"subset\"] == \"val\"].values\n",
        "\n",
        "\n",
        "y_train = df_obs.loc[obs_id_train][\"species_id\"].values\n",
        "y_val = df_obs.loc[obs_id_val][\"species_id\"].values\n",
        "\n",
        "n_val = len(obs_id_val)\n",
        "print(\"Training set size: {} ({:.1%} of train observations)\".format(len(y_train), len(y_train) / len(df_obs)))\n",
        "print(\"Validation set size: {} ({:.1%} of train observations)\".format(n_val, n_val / len(df_obs)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "#imp = SimpleImputer(\n",
        "#    missing_values=np.nan,\n",
        "#    strategy=\"constant\",\n",
        "#    fill_value=np.finfo(np.float32).min,\n",
        "#)\n",
        "df_env = pd.read_csv(\"./geolifeclef-2022-lifeclef-2022-fgvc9/pre-extracted/environmental_vectors.csv\", sep=\";\", index_col=\"observation_id\")\n",
        "a  = df_env.loc(0)\n",
        "columnsNamesArr = df_env.columns.values\n",
        "#print(columnsNamesArr)\n",
        "rowNames = df_env.index.values\n",
        "#print(rowNames)\n",
        "my_imputer = SimpleImputer()\n",
        "#print(df_env.shape)\n",
        "#print(my_imputer.fit_transform(df_env)[0])\n",
        "\n",
        "df_env = pd.DataFrame(my_imputer.fit_transform(df_env))\n",
        "df_env.set_axis(rowNames, axis='index', inplace = True)\n",
        "df_env.set_axis(columnsNamesArr, axis='columns', inplace = True)\n",
        "#print(df_env.shape)\n",
        "\n",
        "df_env.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "wXj3FBy0E97c",
        "outputId": "16bf78be-9a67-4eb0-9892-4493268aa325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-824123ee-b7e0-4dc6-8be2-1486170f782d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bio_1</th>\n",
              "      <th>bio_2</th>\n",
              "      <th>bio_3</th>\n",
              "      <th>bio_4</th>\n",
              "      <th>bio_5</th>\n",
              "      <th>bio_6</th>\n",
              "      <th>bio_7</th>\n",
              "      <th>bio_8</th>\n",
              "      <th>bio_9</th>\n",
              "      <th>bio_10</th>\n",
              "      <th>bio_11</th>\n",
              "      <th>bio_12</th>\n",
              "      <th>bio_13</th>\n",
              "      <th>bio_14</th>\n",
              "      <th>bio_15</th>\n",
              "      <th>bio_16</th>\n",
              "      <th>bio_17</th>\n",
              "      <th>bio_18</th>\n",
              "      <th>bio_19</th>\n",
              "      <th>bdticm</th>\n",
              "      <th>bldfie</th>\n",
              "      <th>cecsol</th>\n",
              "      <th>clyppt</th>\n",
              "      <th>orcdrc</th>\n",
              "      <th>phihox</th>\n",
              "      <th>sltppt</th>\n",
              "      <th>sndppt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10000000</th>\n",
              "      <td>1.420833</td>\n",
              "      <td>6.908333</td>\n",
              "      <td>29.272598</td>\n",
              "      <td>614.14930</td>\n",
              "      <td>15.1</td>\n",
              "      <td>-8.5</td>\n",
              "      <td>23.600000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>9.183333</td>\n",
              "      <td>9.466667</td>\n",
              "      <td>-5.083334</td>\n",
              "      <td>1361.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>20.667326</td>\n",
              "      <td>416.0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>248.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>2082.0</td>\n",
              "      <td>988.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>53.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000001</th>\n",
              "      <td>8.837500</td>\n",
              "      <td>9.858334</td>\n",
              "      <td>37.771393</td>\n",
              "      <td>586.81390</td>\n",
              "      <td>23.8</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>26.099998</td>\n",
              "      <td>6.016667</td>\n",
              "      <td>16.383333</td>\n",
              "      <td>16.383333</td>\n",
              "      <td>2.116667</td>\n",
              "      <td>1109.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>15.231100</td>\n",
              "      <td>314.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>1816.0</td>\n",
              "      <td>1142.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000002</th>\n",
              "      <td>6.241667</td>\n",
              "      <td>8.350000</td>\n",
              "      <td>32.239384</td>\n",
              "      <td>632.86090</td>\n",
              "      <td>21.0</td>\n",
              "      <td>-4.9</td>\n",
              "      <td>25.900000</td>\n",
              "      <td>3.033333</td>\n",
              "      <td>14.200000</td>\n",
              "      <td>14.200000</td>\n",
              "      <td>-1.083333</td>\n",
              "      <td>1288.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>17.713518</td>\n",
              "      <td>386.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>317.0</td>\n",
              "      <td>1346.0</td>\n",
              "      <td>1075.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000003</th>\n",
              "      <td>12.554167</td>\n",
              "      <td>9.525001</td>\n",
              "      <td>40.189877</td>\n",
              "      <td>541.80865</td>\n",
              "      <td>25.9</td>\n",
              "      <td>2.2</td>\n",
              "      <td>23.699999</td>\n",
              "      <td>6.850000</td>\n",
              "      <td>19.350000</td>\n",
              "      <td>19.350000</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>877.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>21.229550</td>\n",
              "      <td>279.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>257.0</td>\n",
              "      <td>1227.0</td>\n",
              "      <td>1383.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000004</th>\n",
              "      <td>8.029167</td>\n",
              "      <td>10.075000</td>\n",
              "      <td>36.636364</td>\n",
              "      <td>633.01750</td>\n",
              "      <td>23.7</td>\n",
              "      <td>-3.8</td>\n",
              "      <td>27.500000</td>\n",
              "      <td>4.616667</td>\n",
              "      <td>16.083334</td>\n",
              "      <td>16.083334</td>\n",
              "      <td>0.766667</td>\n",
              "      <td>1102.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>21.077870</td>\n",
              "      <td>348.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>2833.0</td>\n",
              "      <td>1202.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-824123ee-b7e0-4dc6-8be2-1486170f782d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-824123ee-b7e0-4dc6-8be2-1486170f782d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-824123ee-b7e0-4dc6-8be2-1486170f782d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              bio_1      bio_2      bio_3  ...  phihox  sltppt  sndppt\n",
              "10000000   1.420833   6.908333  29.272598  ...    62.0    34.0    53.0\n",
              "10000001   8.837500   9.858334  37.771393  ...    58.0    41.0    36.0\n",
              "10000002   6.241667   8.350000  32.239384  ...    59.0    40.0    38.0\n",
              "10000003  12.554167   9.525001  40.189877  ...    71.0    46.0    25.0\n",
              "10000004   8.029167  10.075000  36.636364  ...    69.0    38.0    37.0\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs_id_test = df_obs_test.index[:].values\n"
      ],
      "metadata": {
        "id": "aCaE_lShFPaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get subset"
      ],
      "metadata": {
        "id": "eSLqO-sfnvtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "subset_size = 10\n",
        "obs_list = list()\n",
        "import numpy as np\n",
        "# iterate over a subset of the labels\n",
        "counter = 0\n",
        "for y in (np.unique(y_train)[:subset_size]):\n",
        "    # for each label, retrieve all corresponding observation ids\n",
        "    obs = df_obs.index[df_obs[\"species_id\"] == y].values\n",
        "    obs_list.append(obs)\n",
        "    \n",
        "# we now have a numpy array of all observation ids corresponding to this subset of labels\n",
        "obs_id_train = np.concatenate(obs_list)\n",
        "gps_train = np.concatenate((df_obs.loc[obs_id_train][\"latitude\"].values, df_obs.loc[obs_id_train][\"longitude\"].values))\n",
        "# obtain the labels in the right order \n",
        "y_train = df_obs.loc[obs_id_train][\"species_id\"].values\n",
        "print(y_train.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oRZzeUN2AID",
        "outputId": "a89d79ba-526a-4fc9-859e-2c677c77c0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset_size = 8\n",
        "obs_list_1 = list()\n",
        "print(y_val.size)\n",
        "\n",
        "# iterate over a subset of the labels\n",
        "counter = 0\n",
        "for y in (np.unique(y_val)[:subset_size]):\n",
        "    # for each label, retrieve all corresponding observation ids\n",
        "    obs = df_obs.index[df_obs[\"species_id\"] == y].values\n",
        "    obs_list_1.append(obs)\n",
        "# we now have a numpy array of all observation ids corresponding to this subset of labels\n",
        "obs_id_val = np.concatenate(obs_list_1)\n",
        "\n",
        "# obtain the labels in the right order \n",
        "y_val = df_obs.loc[obs_id_val][\"species_id\"].values\n",
        "gps_val = np.concatenate((df_obs.loc[obs_id_val][\"latitude\"].values, df_obs.loc[obs_id_val][\"longitude\"].values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKt6bh2E140O",
        "outputId": "b0104f06-6f98-4cce-c015-46ea6e596253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####PATCH GENERATOR"
      ],
      "metadata": {
        "id": "TBEN485kUF7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "class Patches_Generator(tf.keras.utils.Sequence) :\n",
        "  \n",
        "    def __init__(self, obs_ids, labels, batch_size) :\n",
        "        self.obs_ids = obs_ids\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        # to make the generator thread safe \n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def __len__(self) :\n",
        "        return (np.ceil(len(self.obs_ids) / float(self.batch_size))).astype(int)\n",
        "  \n",
        "    # returns one batch\n",
        "    def __getitem__(self, idx) :\n",
        "        X_batch = list()\n",
        "        y_batch = list()\n",
        "\n",
        "        for i in range(idx * self.batch_size, (idx+1) * self.batch_size):\n",
        "            if i >= len(self.obs_ids): break\n",
        "            \n",
        "            patch = load_patch(self.obs_ids[i], DATA_PATH, data='all')\n",
        "            X_batch.append(patch[0])\n",
        "            y_batch.append(self.labels[i])\n",
        "\n",
        "        with self.lock:\n",
        "            return np.asarray(X_batch), np.array(y_batch)"
      ],
      "metadata": {
        "id": "qeVde2vWUIhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "class Test_Patches_Generator(tf.keras.utils.Sequence) :\n",
        "  \n",
        "    def __init__(self, obs_ids, batch_size) :\n",
        "        self.obs_ids = obs_ids\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        # to make the generator thread safe \n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def __len__(self) :\n",
        "        return (np.ceil(len(self.obs_ids) / float(self.batch_size))).astype(int)\n",
        "  \n",
        "    # returns one batch\n",
        "    def __getitem__(self, idx) :\n",
        "        X_batch = list()\n",
        "        y_batch = list()\n",
        "\n",
        "        for i in range(idx * self.batch_size, (idx+1) * self.batch_size):\n",
        "            if i >= len(self.obs_ids): break\n",
        "            \n",
        "            patch = load_patch(self.obs_ids[i], DATA_PATH, data='rgb')\n",
        "            X_batch.append(patch[0])\n",
        "\n",
        "        with self.lock:\n",
        "            return np.asarray(X_batch)"
      ],
      "metadata": {
        "id": "rUF4dgUSXCTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "class Environmental_Patches_Generator(tf.keras.utils.Sequence) :\n",
        "  \n",
        "    def __init__(self, obs_ids, labels, batch_size) :\n",
        "        self.obs_ids = obs_ids\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        #self.gps = gps\n",
        "        #self.extractor = extractor\n",
        "        #print(\"INIT\")\n",
        "        # to make the generator thread safe \n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def __len__(self) :\n",
        "        return (np.ceil(len(self.obs_ids) / float(self.batch_size))).astype(int)\n",
        "  \n",
        "    # returns one batch\n",
        "    def __getitem__(self, idx) :\n",
        "        X_batch = list()\n",
        "        y_batch = list()\n",
        "        X_env_batch = list()\n",
        "\n",
        "        #print(\"ONE BATCH\")\n",
        "        for i in range(idx * self.batch_size, (idx+1) * self.batch_size):\n",
        "            if i >= len(self.obs_ids): break\n",
        "            \n",
        "            rgb, near_ir, landcover, altitude = load_patch(self.obs_ids[i], DATA_PATH, data='all')\n",
        "            ni = near_ir.reshape(256, 256, 1)\n",
        "            lc = landcover.reshape(256, 256, 1)\n",
        "            alt = altitude.reshape(256, 256, 1)\n",
        "\n",
        "            patch = np.concatenate((rgb, ni, lc, alt), axis=2)\n",
        "\n",
        "  \n",
        "            #cs = MinMaxScaler()\n",
        "            #print(\"PATCH GENERATOR\")\n",
        "            #print((df_env.loc[self.obs_ids[i]].values).shape)\n",
        "            #print(cs.fit_transform(df_env.loc[self.obs_ids[i]].values).shape)\n",
        "            #k = input()\n",
        "            X_env_batch.append(df_env.loc[self.obs_ids[i]].values)\n",
        "            #X_env_batch.append(df_env[self.obs_ids[i], :])\n",
        "            #X_env_batch.append(cs.fit_transform(df_env.loc[self.obs_ids[i]].values.reshape(-1,1)))\n",
        "            X_batch.append(patch)\n",
        "            y_batch.append(self.labels[i])\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "        with self.lock:\n",
        "        \n",
        "            \n",
        "            #return {'input_1': np.asarray(X_batch), 'input_2': np.asarray(X_env_batch)}, np.asarray(np.array(y_batch))\n",
        "            #return np.asarray(X_batch), np.array(y_batch)\n",
        "            return (np.asarray(X_batch), np.asarray(X_env_batch)), np.array(y_batch)"
      ],
      "metadata": {
        "id": "2cFjcJLQL1N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pretrained Patches"
      ],
      "metadata": {
        "id": "ojcG8LZnrJeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "class Pretrained_Patches_Generator(tf.keras.utils.Sequence) :\n",
        "  \n",
        "    def __init__(self, obs_ids, labels, batch_size) :\n",
        "        self.obs_ids = obs_ids\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        #self.gps = gps\n",
        "        #self.extractor = extractor\n",
        "        #print(\"INIT\")\n",
        "        # to make the generator thread safe \n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def __len__(self) :\n",
        "        return (np.ceil(len(self.obs_ids) / float(self.batch_size))).astype(int)\n",
        "  \n",
        "    # returns one batch\n",
        "    def __getitem__(self, idx) :\n",
        "        X_batch_rgb = list()\n",
        "        X_batch_images = list()\n",
        "        y_batch = list()\n",
        "        X_env_batch = list()\n",
        "\n",
        "        #print(\"ONE BATCH\")\n",
        "        for i in range(idx * self.batch_size, (idx+1) * self.batch_size):\n",
        "            if i >= len(self.obs_ids): break\n",
        "            \n",
        "            rgb, near_ir, landcover, altitude = load_patch(self.obs_ids[i], DATA_PATH, data='all')\n",
        "            ni = near_ir.reshape(256, 256, 1)\n",
        "            lc = landcover.reshape(256, 256, 1)\n",
        "            alt = altitude.reshape(256, 256, 1)\n",
        "\n",
        "            patch1 = np.concatenate((ni, lc, alt), axis=2)\n",
        "\n",
        "  \n",
        "            #cs = MinMaxScaler()\n",
        "            #print(\"PATCH GENERATOR\")\n",
        "            #print((df_env.loc[self.obs_ids[i]].values).shape)\n",
        "            #print(cs.fit_transform(df_env.loc[self.obs_ids[i]].values).shape)\n",
        "            #k = input()\n",
        "            X_env_batch.append(df_env.loc[self.obs_ids[i]].values)\n",
        "            #X_env_batch.append(df_env[self.obs_ids[i], :])\n",
        "            #X_env_batch.append(cs.fit_transform(df_env.loc[self.obs_ids[i]].values.reshape(-1,1)))\n",
        "            X_batch_rgb.append(rgb)\n",
        "            X_batch_images.append(patch1)\n",
        "            y_batch.append(self.labels[i])\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "        with self.lock:\n",
        "        \n",
        "            \n",
        "            #print(len(X_batch_images))\n",
        "            #print(len(X_batch_rgb))\n",
        "            #print(np.asarray(X_batch_images).shape)\n",
        "            #print(\"AH\")\n",
        "            #return {'input_1': np.asarray(X_batch), 'input_2': np.asarray(X_env_batch)}, np.asarray(np.array(y_batch))\n",
        "            #return np.asarray(X_batch), np.array(y_batch)\n",
        "            return (np.asarray(X_batch_rgb), np.asarray(X_batch_images), np.asarray(X_env_batch)), np.array(y_batch)"
      ],
      "metadata": {
        "id": "kZNU6rSErIKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOS1SPT06wBz"
      },
      "source": [
        "### Load patches"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j1LeYtLBoUDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugYEUL1D6wB4"
      },
      "source": [
        "# First Simple Neural Network\n",
        "Let's create a first neural network as a baseline to see how it performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs3aLA5L6wB4"
      },
      "outputs": [],
      "source": [
        "# returns a 10 layer ReLU model of width 2\n",
        "def simple_model(input_shape):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    # 1. Preprocessing\n",
        "    # rescale inputs\n",
        "    model.add(tf.keras.layers.Rescaling(1./255))\n",
        "\n",
        "    # 2. Convolutional Layers\n",
        "    model.add(Conv2D(32, kernel_size=5, activation='relu', input_shape=input_shape, padding='same'))\n",
        "    #model.add(AveragePooling2D())\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=5, activation='relu', padding='same'))\n",
        "    #model.add(AveragePooling2D())\n",
        "    \n",
        "    model.add(Conv2D(128, kernel_size=5, activation='relu', padding='same'))\n",
        "    \n",
        "    # from convolutional layers to dense layers\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    \n",
        "    # 3. Dense Layers\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    \n",
        "    # 4. Output Layer\n",
        "    model.add(Dense(4911, activation='softmax'))\n",
        "    \n",
        "    # compire the model\n",
        "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpurXLkg6wB5"
      },
      "outputs": [],
      "source": [
        "# create the network\n",
        "model = simple_model((256, 256, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xcce0V4A6wB5"
      },
      "outputs": [],
      "source": [
        "np.max(y_train[:len(X_train)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7BjcAiR6wB5"
      },
      "outputs": [],
      "source": [
        "np.min(y_train[:len(X_train)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAqfXz4Y6wB6"
      },
      "source": [
        "Train the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjGb-Lp96wB6"
      },
      "outputs": [],
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0.001, patience=5, \n",
        "                                              verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "gB7f0t-i6wB6"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_ds, validation_data=val_ds, #X_train, y_train[:len(X_train)], #validation_data=(X_val, y_val), \n",
        "                    epochs=100, \n",
        "                    callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoEYkjJ36wB6"
      },
      "outputs": [],
      "source": [
        "model.save('first_simple_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kennedy's ResNet From Scratch"
      ],
      "metadata": {
        "id": "4-8ZzwPeoaTU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuNgS5Pa6wB7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "def identity_block(x, filter):\n",
        "  x_skip = x\n",
        "  x = tf.keras.layers.Conv2D(filter[0], (3,3), padding = \"same\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  #print(\"A\")\n",
        "  x = tf.keras.layers.Conv2D(filter[1], (3,3), padding = \"same\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Add()([x, x_skip])\n",
        "\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def conv_net(x, filter):\n",
        "  \n",
        "  x_skip = x\n",
        "  #print(\"B\")\n",
        "  x = tf.keras.layers.Conv2D(filter[0], (3,3), strides = 2, padding = \"same\")(x)\n",
        "  #print(\"C\")\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  #print(\"D\")\n",
        "  x = tf.keras.layers.Conv2D(filter[0], (3,3), padding = \"same\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  #print(\"E\")\n",
        "  x_skip = tf.keras.layers.Conv2D(filter[1], (1,1), strides = 2, padding = \"same\")(x_skip)\n",
        "  x = tf.keras.layers.Add()([x, x_skip])\n",
        "  #print(\"F\")\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "#input 1 is for image data, input 2 is for tabular data\n",
        "def my_res(input_shape1, input_shape2, num_classes):\n",
        "  x_input = tf.keras.layers.Input(input_shape)\n",
        "  x = tf.keras.layers.Rescaling(1./255)(x_input)\n",
        "  x = tf.keras.layers.ZeroPadding2D(padding = (3,3))(x)\n",
        "\n",
        "  \n",
        "  #print(\"a\")\n",
        "  x = tf.keras.layers.Conv2D(64, 7 , strides = 2, padding = \"same\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides = (2,2), padding = \"same\")(x)\n",
        "\n",
        "  #print(x.shape)\n",
        "  #print('b')\n",
        "  x = conv_net(x, (64, 64))\n",
        "  #print('c')\n",
        "  x = identity_block(x, (64, 64))\n",
        "\n",
        "  #print('d')\n",
        "  x = conv_net(x, (128, 128))\n",
        "  x = identity_block(x, (128, 128))\n",
        "  x = identity_block(x, (128, 128))\n",
        "  #x = identity_block(x, (128, 128))\n",
        "\n",
        "  x = conv_net(x, (256, 256))\n",
        "  x = identity_block(x, (256, 256))\n",
        "  x = identity_block(x, (256, 256))\n",
        "  x = identity_block(x, (256, 256))\n",
        "  x = identity_block(x, (256, 256))\n",
        "\n",
        "  x = tf.keras.layers.AveragePooling2D(padding = \"same\")(x)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  x = tf.keras.layers.Dense(num_classes, activation = 'softmax')(x)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"resnet_from_scratch\")\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Kennedy's ResNet Modified to take in image + tabular "
      ],
      "metadata": {
        "id": "1uqttvwvTDi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def identity_block(x, filter):\n",
        "  x_skip = x\n",
        "  x = tf.keras.layers.Conv2D(filter[0], (3,3), padding = \"same\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  #print(\"A\")\n",
        "  x = tf.keras.layers.Conv2D(filter[1], (3,3), padding = \"same\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Add()([x, x_skip])\n",
        "\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def conv_net(x, filter):\n",
        "  \n",
        "  x_skip = x\n",
        "  #print(\"B\")\n",
        "  x = tf.keras.layers.Conv2D(filter[0], (3,3), strides = 2, padding = \"same\")(x)\n",
        "  #print(\"C\")\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  #print(\"D\")\n",
        "  x = tf.keras.layers.Conv2D(filter[0], (3,3), padding = \"same\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  #print(\"E\")\n",
        "  x_skip = tf.keras.layers.Conv2D(filter[1], (1,1), strides = 2, padding = \"same\")(x_skip)\n",
        "  x = tf.keras.layers.Add()([x, x_skip])\n",
        "  #print(\"F\")\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "#input 1 is for image data, input 2 is for tabular data\n",
        "def my_res(input_shape1, input_shape2, num_classes):\n",
        "  x_input = tf.keras.layers.Input(input_shape1)\n",
        "  tab_input = tf.keras.layers.Input(input_shape2)\n",
        "  x_input = tf.keras.layers.Rescaling(1./255)(x_input)\n",
        "  x = tf.keras.layers.ZeroPadding2D(padding = (3,3))(x_input)\n",
        "\n",
        "  #print(\"a\")\n",
        "  x = tf.keras.layers.Conv2D(64, 7, strides = 2, padding = \"same\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides = (2,2), padding = \"same\")(x)\n",
        "\n",
        "  #print(x.shape)\n",
        "  #print('b')\n",
        "  x = conv_net(x, (64, 64))\n",
        "  #print('c')\n",
        "  x = identity_block(x, (64, 64))\n",
        "\n",
        "  #print('d')\n",
        "  x = conv_net(x, (128, 128))\n",
        "  x = identity_block(x, (128, 128))\n",
        "  x = identity_block(x, (128, 128))\n",
        "  #x = identity_block(x, (128, 128))\n",
        "\n",
        "  x = conv_net(x, (256, 256))\n",
        "  x = identity_block(x, (256, 256))\n",
        "  x = identity_block(x, (256, 256))\n",
        "  x = identity_block(x, (256, 256))\n",
        "  x = identity_block(x, (256, 256))\n",
        "\n",
        "  x = tf.keras.layers.AveragePooling2D(padding = \"same\")(x)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  \n",
        "  #x = tf.keras.layers.Dense(num_classes, activation = 'softmax')(x)\n",
        "\n",
        "\n",
        "  # Add Dense layers for Tabular data\n",
        "  #y = tf.keras.layers.Dense(512)(tab_input)\n",
        "  #y = tf.keras.layers.Dense(256)(tab_input)\n",
        "  #y = tf.keras.layers.Dense(256)(x)\n",
        "  #y = tf.keras.layers.Dense(256)(tab_input)\n",
        "  #FROM stackoverflow\n",
        "  x2 = tf.keras.layers.Flatten(name=\"flatten_csv\")(tab_input)\n",
        "  x2 = tf.keras.layers.Dense(32, activation='leaky_relu', name=\"dense1_csv\")(x2)\n",
        "  x2 = tf.keras.layers.Dense(128, activation='leaky_relu', name=\"dense2_csv\")(x2)\n",
        "  x2 = tf.keras.layers.Dense(256, activation='leaky_relu', name=\"dense3_csv\")(x2)\n",
        "  x2 = tf.keras.layers.Dense(6400, activation='leaky_relu')(x2)\n",
        "  #print(x[0])\n",
        "  #print(x2[0])\n",
        "  #k = input()\n",
        "  #print(x.shape)\n",
        "  #print(x2.shape)\n",
        "  \n",
        "  #k = input()\n",
        "  # Concatenate Image and tabular weights\n",
        "  z = tf.keras.layers.Concatenate(axis=1)([x, x2])\n",
        "\n",
        "  \n",
        "  # Add Classification Head\n",
        "  #z = tf.keras.layers.Dense(128)(z)\n",
        "  classifier = tf.keras.layers.Dense(num_classes, activation='softmax')(z)\n",
        "\n",
        "  #classifier = tf.keras.layers.Dense(num_classes, name='outputs', activation='softmax')(x)\n",
        "  model = tf.keras.models.Model(inputs = [x_input, tab_input], outputs = classifier, name = \"resnet_tab_plus_image\")\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "egJKniHLTAqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pre-Trained ResNet-50"
      ],
      "metadata": {
        "id": "iEow7NARi4cx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oVszMXT70bd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.image_ops_impl import rgb_to_grayscale\n",
        "num_classes = len(set(df_obs['species_id']))\n",
        "#pre_trained_res = Sequential()\n",
        "\n",
        "\n",
        "#FROM https://chroniclesofai.com/transfer-learning-with-keras-resnet-50/\n",
        "#for layer in res_img.layers:\n",
        "#        layer.trainable=False\n",
        "\n",
        "def transfer_learning(input_shape1, input_shape2, input_shape3, num_classes):\n",
        "    #print(\"MADE IT\")\n",
        "    #image = tf.image.resize(image, (INP_SIZE[0], INP_SIZE[1]))\n",
        "\n",
        "    res_img = tf.keras.applications.resnet50.ResNet50(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    #input_tensor=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling='none',\n",
        "    classes=num_classes,\n",
        "    )\n",
        "    \n",
        "    #print(input_shape1)\n",
        "    #print(input_shape2)\n",
        "    for layer in res_img.layers:\n",
        "      layer.trainable = False\n",
        "    rgb_input = tf.keras.layers.Input(input_shape1)\n",
        "    #print(\"A\")\n",
        "    img_input = tf.keras.layers.Input(input_shape2)\n",
        "    rgb = tf.keras.layers.Conv2D(3, kernel_size=(33, 33), activation='relu')(rgb_input)\n",
        "    scale_layer = tf.keras.layers.Rescaling(scale=1 / 255, offset=-1)\n",
        "    rgb = scale_layer(rgb)  \n",
        "    #img = tf.keras.layers.Conv2D(8, kernel_size=(33, 33), activation='relu')(img_input)\n",
        "    #print(rgb)\n",
        "    tab_input = tf.keras.layers.Input(input_shape3)\n",
        "    #print(\"B\")\n",
        "    rgb = res_img(rgb, training = False)\n",
        "    #rgb = tf.keras.layers.GlobalAveragePooling2D()(rgb)\n",
        "    #rgb = tf.keras.layers.Conv2D(3, (3,3), strides = 32)(rgb)\n",
        "  #print(\"C\")\n",
        "    #rgb = tf.keras.layers.BatchNormalization()(rgb)\n",
        "    #rgb = tf.keras.layers.Activation('relu')(rgb)\n",
        "    #rgb = tf.keras.layers.Conv2D(3, (9,9), strides = 2, padding = \"same\")(rgb)\n",
        "  #print(\"C\")\n",
        "    #rgb = tf.keras.layers.BatchNormalization()(rgb)\n",
        "    #rgb = tf.keras.layers.Activation('relu')(rgb)\n",
        "    #rgb = tf.keras.layers.Conv2D(3, (9,9), strides = 2, padding = \"same\")(rgb)\n",
        "  #print(\"C\")\n",
        "    #rgb = tf.keras.layers.BatchNormalization()(rgb)\n",
        "    #rgb = tf.keras.layers.Activation('relu')(rgb)\n",
        "    #print(\"C\")\n",
        "    #rgb = tf.keras.layers.Flatten()(rgb)\n",
        "    #print(\"D\")\n",
        "    img = img_input\n",
        "    #img = res_img(img_input, training = False)\n",
        "    rgb = tf.keras.layers.Dense(32, activation = 'relu')(rgb)\n",
        "    rgb = tf.keras.layers.Flatten()(rgb)\n",
        "\n",
        "    \n",
        "    #rgb = tf.keras.layers.GlobalAveragePooling2D()(rgb)\n",
        "    #rgb = tf.keras.layers.Dropout(0.2)(rgb)  # Regularize with dropout\n",
        "    \n",
        "\n",
        "    #img = tf.keras.layers.GlobalAveragePooling2D()(img)\n",
        "    #img = tf.keras.layers.Dropout(0.2)(img)  # Regularize with dropout\n",
        "\n",
        "    #z = tf.keras.layers.Concatenate(axis=1)([rgb, img])\n",
        "\n",
        "    classifier = tf.keras.layers.Dense(num_classes, activation='softmax')(rgb)\n",
        "\n",
        "  #classifier = tf.keras.layers.Dense(num_classes, name='outputs', activation='softmax')(x)\n",
        "    model = tf.keras.models.Model(inputs = [rgb_input, img_input, tab_input], outputs = classifier, name = \"pre-t-all-imag\")\n",
        "    #for layer in res_img.layers:\n",
        "    #    layer.trainable=False\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tJTm-MQji7EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For Images (Includes RGB, near IR, landcover, altitude) + Tabular (environmental vectors)"
      ],
      "metadata": {
        "id": "lzjAB49wo0hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCHSIZE = 128\n",
        "train_generator = Environmental_Patches_Generator(obs_id_train, y_train, BATCHSIZE)\n",
        "print(\"HERRE\")\n",
        "val_generator = Environmental_Patches_Generator(obs_id_val, y_val, BATCHSIZE)\n",
        "\n",
        "# converting our train dataset to tf.data.Dataset\n",
        "tf_train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: train_generator ,  # Our generator \n",
        "    output_types = ({'input_1': tf.float32 , 'input_2': tf.float32}, tf.float32) , # How we're expecting our output dtype\n",
        "#    output_shapes = ({'input_1': [BATCH_SIZE, 256 , 256, 6], 'input_2': [BATCH_SIZE, 29]} , [BATCH_SIZE, ]) # How we're expecting our output shape\n",
        ")\n",
        "\n",
        "tf_val_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: val_generator , \n",
        "    output_types = ({'input_1': tf.float32 , 'input_2': tf.float32}, tf.float32),\n",
        "#    output_shapes = ({'input_1': [BATCH_SIZE, 256 , 256, 6], 'input_2': [BATCH_SIZE, 29]} , [BATCH_SIZE, ]) \n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "num_classes = len(set(df_obs['species_id']))\n",
        "\n",
        "input_shape1 = (256, 256, 6)\n",
        "input_shape2 = (27)\n",
        "model = my_res(input_shape1, input_shape2, num_classes)\n",
        "# Compile model\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[\n",
        "                  tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "                  tf.keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\")\n",
        "              ]\n",
        "              )\n"
      ],
      "metadata": {
        "id": "NHSmCz5DozSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "661d8389-165d-456c-8173-b49440c3e2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERRE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pre-Trained All Images Code"
      ],
      "metadata": {
        "id": "qJc4ztWEps5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCHSIZE = 64\n",
        "train_generator = Pretrained_Patches_Generator(obs_id_train, y_train, BATCHSIZE)\n",
        "print(\"HERRE\")\n",
        "val_generator = Pretrained_Patches_Generator(obs_id_val, y_val, BATCHSIZE)\n",
        "\n",
        "# converting our train dataset to tf.data.Dataset\n",
        "#tf_train_dataset = tf.data.Dataset.from_generator(\n",
        "#    lambda: train_generator ,  # Our generator \n",
        "#    output_types = ({'input_1': tf.float32 , 'input_2': tf.float32, 'input_3': tf.float32}, tf.float32) , # How we're expecting our output dtype\n",
        "#    output_shapes = ({'input_1': [BATCH_SIZE, 256 , 256, 6], 'input_2': [BATCH_SIZE, 29]} , [BATCH_SIZE, ]) # How we're expecting our output shape\n",
        "#)\n",
        "\n",
        "#tf_val_dataset = tf.data.Dataset.from_generator(\n",
        "#    lambda: val_generator , \n",
        "#    output_types = ({'input_1': tf.float32 , 'input_2': tf.float32, 'input_3': tf.float32}, tf.float32),\n",
        "#    output_shapes = ({'input_1': [BATCH_SIZE, 256 , 256, 6], 'input_2': [BATCH_SIZE, 29]} , [BATCH_SIZE, ]) \n",
        "#)\n",
        "\n",
        "\n",
        "#PROBLEM\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "num_classes = len(set(df_obs['species_id']))\n",
        "#num_classes = 10\n",
        "input_shape1 = (256, 256, 3)\n",
        "input_shape2 = (256, 256, 3)\n",
        "input_shape3 = (27)\n",
        "model1 = transfer_learning(input_shape1, input_shape2, input_shape3, num_classes)\n",
        "# Compile model\n",
        "model1.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[\n",
        "                  tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "                  tf.keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\")\n",
        "              ]\n",
        "              )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swIy3cu2prs8",
        "outputId": "9b072f57-4166-4cdb-9ffd-50b6a0db6210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HERRE\n",
            "Model: \"pre-t-all-imag\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_226 (InputLayer)         [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 224, 224, 3)  9804        ['input_226[0][0]']              \n",
            "                                                                                                  \n",
            " rescaling_9 (Rescaling)        (None, 224, 224, 3)  0           ['conv2d_91[0][0]']              \n",
            "                                                                                                  \n",
            " resnet50 (Functional)          (None, 7, 7, 2048)   23587712    ['rescaling_9[0][0]']            \n",
            "                                                                                                  \n",
            " dense_53 (Dense)               (None, 7, 7, 32)     65568       ['resnet50[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_63 (Flatten)           (None, 1568)         0           ['dense_53[0][0]']               \n",
            "                                                                                                  \n",
            " input_227 (InputLayer)         [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_228 (InputLayer)         [(None, 27)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_54 (Dense)               (None, 17037)        26731053    ['flatten_63[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 50,394,137\n",
            "Trainable params: 26,806,425\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For GPS"
      ],
      "metadata": {
        "id": "mcSrMF_Vo2tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001 )\n",
        "num_classes = len(set(df_obs['species_id']))\n",
        "input_shape = (2,1)\n",
        "model_1 = my_res(input_shape, num_classes)\n",
        "# Compile model\n",
        "model_1.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[\n",
        "                  tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "                  tf.keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\")\n",
        "              ]\n",
        "              )"
      ],
      "metadata": {
        "id": "FdljaDPSo4pk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "aa802806-8cf7-4e70-f6a3-1e3a2ae3d049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a69906c61d32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'species_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Compile model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m model_1.compile(optimizer=optimizer,\n",
            "\u001b[0;32m<ipython-input-24-d6e2f1abba74>\u001b[0m in \u001b[0;36mmy_res\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmy_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;31m#print(\"a\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[1;32m    214\u001b[0m                          \u001b[0;34m'is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                          \u001b[0;34mf'expected ndim={spec.ndim}, found ndim={ndim}. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"zero_padding2d_2\" is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (None, 2, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For Environmental Vectors"
      ],
      "metadata": {
        "id": "bbeabZ8QHA-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_env = pd.read_csv(\"./geolifeclef-2022-lifeclef-2022-fgvc9/pre-extracted/environmental_vectors.csv\", sep=\";\", index_col=\"observation_id\")\n",
        "\n",
        "X_train = df_env.loc[obs_id_train].values\n",
        "X_val = df_env.loc[obs_id_val].values\n",
        "X_test = df_env.loc[obs_id_test].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKCXEDZVHARU",
        "outputId": "49acb8f6-623a-49b5-d30b-bcdb416c65b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extractor = PatchExtractor(\"./geolifeclef-2022-lifeclef-2022-fgvc9/pre-extracted/rasters\", size=256)\n",
        "extractor.add_all_bioclimatic_rasters()\n"
      ],
      "metadata": {
        "id": "9wLCbjkhKQEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Model"
      ],
      "metadata": {
        "id": "YUpKMJCQJpuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0.001, patience=10, \n",
        "                                            verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
        "train_results = model.fit(\n",
        "    #train_ds,\n",
        "    train_generator,\n",
        "    validation_data = val_generator,\n",
        "    #tf_train_dataset,\n",
        "    #validation_data= val_ds,\n",
        "    #validation_data = tf_val_dataset,\n",
        "    epochs = 100,\n",
        "    callbacks=[early_stop])\n",
        "#)\n",
        "# callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "cpfxWC7F4PQK",
        "outputId": "7e716e1b-03cf-4181-eb3c-e3b82f633a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-9392e4e20f21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0.001, patience=10, \n\u001b[1;32m      2\u001b[0m                                             verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n\u001b[0;32m----> 3\u001b[0;31m train_results = model.fit(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#train_ds,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "04Xc4Ow-qmSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Model Pretrained"
      ],
      "metadata": {
        "id": "zgsusc2oqpEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0.001, patience=10, \n",
        "                                            verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
        "train_results = model1.fit(\n",
        "    #train_ds,\n",
        "    train_generator,\n",
        "    validation_data = val_generator,\n",
        "    #tf_train_dataset,\n",
        "    #validation_data= val_ds,\n",
        "    #validation_data = tf_val_dataset,\n",
        "    epochs = 100,\n",
        "    callbacks=[early_stop])\n",
        "#)\n",
        "# callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "EjAk6p47qrNf",
        "outputId": "d65a793e-cb7e-4a1f-b852-83330f7c839c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  266/24804 [..............................] - ETA: 3:38:42 - loss: 8.7786 - accuracy: 0.0031 - top-5-accuracy: 0.0150"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-168-cbd1991fbe8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#validation_data = tf_val_dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     callbacks=[early_stop])\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# callbacks=[early_stop])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Submission"
      ],
      "metadata": {
        "id": "Ks-Hm0K6N1rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = Test_Patches_Generator(obs_id_test, BATCHSIZE)\n",
        "\n",
        "tf_test_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: test_generator,  # Our generator \n",
        "    output_types = (tf.float32 , tf.float32), # How we're expecting our output dtype\n",
        "    #output_shapes = ([BATCHSIZE, 256 , 256, 3] , [BATCHSIZE, ]) # How we're expecting our output shape\n",
        "    #output_shapes = (tf.TensorShape(features_shape), [BATCHSIZE, ]),\n",
        ")"
      ],
      "metadata": {
        "id": "Nj_vHzB9TQCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "SUBMISSION_PATH = Path(\"submissions\")\n",
        "os.makedirs(SUBMISSION_PATH, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "fqbiABH4_i6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from GLC.submission import generate_submission_file\n",
        "\n",
        "\n",
        "n_test = len(df_obs_test)\n",
        "s_pred = model.predict_generator(test_generator)\n",
        "\n",
        "# Generate the submission file\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "0Kc4vUAlAZoC",
        "outputId": "a9ba16ce-2f0d-407f-af9b-649b52cd6e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-4320672829e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Generate the submission file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgenerate_submission_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUBMISSION_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"constant_top_30_most_present_species_baseline.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_obs_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'SUBMISSION_PATH' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(s_pred[11])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "rIJpYev9P9U8",
        "outputId": "b274faee-1a1c-4530-8ebd-84be45916cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b4c2f3e027fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 's_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_submission_file(\"./submissions/new\", df_obs_test.index, s_pred)"
      ],
      "metadata": {
        "id": "Wa6Qr79tPC4E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Kennedy res_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eSLqO-sfnvtQ",
        "mcSrMF_Vo2tj",
        "bbeabZ8QHA-7",
        "Ks-Hm0K6N1rC"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}