{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U tensorflow-addons\n",
    "# !pip install huggingface-hub\n",
    "# !pip install transformers\n",
    "# !pip install datasets\n",
    "# !pip install rtdl\n",
    "# !pip install multimodal-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# disable gradient warning because of axes swap\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Add, GlobalAveragePooling2D, Conv2D, Dense, AveragePooling2D, BatchNormalization, Dropout, Flatten, Lambda, Input, Activation\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import schedules, SGD\n",
    "from tensorflow.keras.callbacks import Callback, TensorBoard as TensorboardCallback, EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from utils.custom_layers import SwapAxes\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from huggingface_hub import notebook_login, HfFolder, HfApi\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import scale\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import copy\n",
    "import threading\n",
    "import opendatasets as od\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import cartopy\n",
    "\n",
    "from GLC.data_loading.common import load_patch\n",
    "\n",
    "%pylab inline --no-import-all\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "hours = 4\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this path to adapt to where you downloaded the data\n",
    "DATA_PATH = Path(\"./geolifeclef-2022-lifeclef-2022-fgvc9/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for training: 1627475\n",
      "Number of observations for testing: 36421\n",
      "Number of data sources: 4\n",
      "Arrays shape: [(256, 256, 3), (256, 256), (256, 256), (256, 256)]\n",
      "Data types: [dtype('uint8'), dtype('uint8'), dtype('int16'), dtype('uint8')]\n"
     ]
    }
   ],
   "source": [
    "### Training Dataset ###\n",
    "# let's load the data from file\n",
    "df_obs_fr = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "\n",
    "df_obs = pd.concat((df_obs_fr, df_obs_us))\n",
    "\n",
    "print(\"Number of observations for training: {}\".format(len(df_obs)))\n",
    "\n",
    "### Test Dataset ###\n",
    "df_obs_fr_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "\n",
    "df_obs_test = pd.concat((df_obs_fr_test, df_obs_us_test))\n",
    "\n",
    "print(\"Number of observations for testing: {}\".format(len(df_obs_test)))\n",
    "\n",
    "df_suggested_landcover_alignment = pd.read_csv(DATA_PATH / \"metadata\" / \"landcover_suggested_alignment.csv\", sep=\";\")\n",
    "\n",
    "obs_id_train = df_obs.index[df_obs[\"subset\"] == \"train\"].values\n",
    "obs_id_val = df_obs.index[df_obs[\"subset\"] == \"val\"].values\n",
    "\n",
    "y_train = df_obs.loc[obs_id_train][\"species_id\"].values\n",
    "y_val = df_obs.loc[obs_id_val][\"species_id\"].values\n",
    "\n",
    "patch = load_patch(10171444, DATA_PATH)\n",
    "\n",
    "print(\"Number of data sources: {}\".format(len(patch)))\n",
    "print(\"Arrays shape: {}\".format([p.shape for p in patch]))\n",
    "print(\"Data types: {}\".format([p.dtype for p in patch]))\n",
    "\n",
    "landcover_mapping = df_suggested_landcover_alignment[\"suggested_landcover_code\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Val Split Labels\n",
    "Retrieve the train/val split provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1587395 (97.5% of train observations). Number of training labels: 17031.\n",
      "Validation set size: 40080 (2.5% of train observations). Number of validation labels: 6661.\n",
      "Number of labels in validation set but not in train set: 6\n"
     ]
    }
   ],
   "source": [
    "train_labels = df_obs.loc[obs_id_train][\"species_id\"].values\n",
    "val_labels = df_obs.loc[obs_id_val][\"species_id\"].values\n",
    "\n",
    "n_val = len(obs_id_val)\n",
    "n_train = len(obs_id_train)\n",
    "\n",
    "print(\"Training set size: {} ({:.1%} of train observations). Number of training labels: {}.\".format(n_train, n_train / len(df_obs), len(set(train_labels))))\n",
    "print(\"Validation set size: {} ({:.1%} of train observations). Number of validation labels: {}.\".format(n_val, n_val / len(df_obs), len(set(val_labels))))\n",
    "print(\"Number of labels in validation set but not in train set: {}\".format(len(set(val_labels) - set(train_labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_labels(labels, subset_size=1000):\n",
    "    '''\n",
    "    Select only a subset of labels\n",
    "    '''\n",
    "    obs_list = list()\n",
    "\n",
    "    # iterate over a subset of the labels\n",
    "    counter = 0\n",
    "    for label in np.unique(labels)[:subset_size]:\n",
    "        # for each label, retrieve all corresponding observation ids\n",
    "        obs = df_obs.index[df_obs[\"species_id\"] == label].values\n",
    "        obs_list.append(obs)\n",
    "\n",
    "    # we now have a numpy array of all observation ids corresponding to this subset of labels\n",
    "    X = np.concatenate(obs_list)\n",
    "\n",
    "    # obtain the labels in the right order \n",
    "    Y = df_obs.loc[X][\"species_id\"].values\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches_Generator(tf.keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, obs_ids, labels, batch_size) :\n",
    "        self.obs_ids = obs_ids\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # to make the generator thread safe \n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.floor(len(self.obs_ids) / float(self.batch_size))).astype(int)\n",
    "  \n",
    "    # returns one batch\n",
    "    def __getitem__(self, idx) :\n",
    "        X_batch = list()\n",
    "        y_batch = list()\n",
    "\n",
    "        for i in range(idx * self.batch_size, (idx+1) * self.batch_size):\n",
    "            if i >= len(self.obs_ids): break\n",
    "            \n",
    "            patch = load_patch(self.obs_ids[i], DATA_PATH, data='rgb')\n",
    "            # Swap axes for transformer, which needs channels as first dimension\n",
    "            X_batch.append(patch[0])\n",
    "            y_batch.append(self.labels[i])\n",
    "\n",
    "        with self.lock:\n",
    "            return np.asarray(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_value_counts = df_obs[\"species_id\"].value_counts()\n",
    "species_value_counts[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches_Generator_Two(tf.keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, obs_ids, labels, batch_size) :\n",
    "        self.obs_ids = obs_ids\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # to make the generator thread safe \n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.floor(len(self.obs_ids) / float(self.batch_size))).astype(int)\n",
    "  \n",
    "    # returns one batch\n",
    "    def __getitem__(self, idx) :\n",
    "        X_batch = list()\n",
    "        y_batch = list()\n",
    "\n",
    "        for i in range(idx * int(self.batch_size/2), (idx+1) * int(self.batch_size/2)):\n",
    "            if i >= len(self.obs_ids): break\n",
    "            \n",
    "            rgb, near_ir, landcover, altitude = load_patch(self.obs_ids[i], DATA_PATH)\n",
    "\n",
    "            ni = near_ir.reshape(256, 256, 1)\n",
    "            lc = landcover.reshape(256, 256, 1)\n",
    "            alt = altitude.reshape(256, 256, 1)\n",
    "\n",
    "            patch = np.concatenate((ni, lc, alt), axis=2)\n",
    "            \n",
    "            # add rgb as one observation\n",
    "            X_batch.append(rgb)\n",
    "            y_batch.append(self.labels[i])\n",
    "            \n",
    "            # rest of data as second observation\n",
    "            X_batch.append(patch)\n",
    "            y_batch.append(self.labels[i])\n",
    "\n",
    "        with self.lock:\n",
    "            return np.asarray(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Pre-trained Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Login to HuggingFace\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose pre-trained transformer\n",
    "model_id = \"philschmid/vit-base-patch16-224-in21k-euroSat\"\n",
    "\n",
    "input_size = 256\n",
    "input_channels = 3\n",
    "input_shape = (input_size, input_size, input_channels)\n",
    "output_dir=model_id.split(\"/\")[1]\n",
    "hub_token = \"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\" # or your token directly \"hf_xxx\"\n",
    "hub_model_id = f'{model_id.split(\"/\")[1]}-species-prediction'\n",
    "fp16=True\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "# Comment this line out if you're using a GPU that will not benefit from this\n",
    "if fp16:\n",
    "    keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 3e-5\n",
    "NUM_CLASSES = 20\n",
    "weight_decay_rate=0.005\n",
    "num_warmup_steps=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.data_loader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.data_loader' from '/home/jjw2196/species-presence-prediction/utils/data_loader.py'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dl.DataLoader(data_path=\"./geolifeclef-2022-lifeclef-2022-fgvc9/\")\n",
    "\n",
    "train_ids, y_train = loader.subset_labels(num_labels=10, set_type='train')\n",
    "val_ids, y_val = loader.subset_labels(num_labels=10, set_type='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader2.subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx, y_train = subset_labels(train_labels, subset_size = NUM_CLASSES)\n",
    "X_val_idx, y_val = subset_labels(val_labels, subset_size = NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Patches_Generator(X_train_idx, y_train, BATCH_SIZE)\n",
    "val_data = Patches_Generator(X_val_idx, y_val, BATCH_SIZE)\n",
    "\n",
    "# converting our train dataset to tf.data.Dataset\n",
    "tf_train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_data ,  # Our generator \n",
    "    output_types = (tf.float32 , tf.float32) , # How we're expecting our output dtype\n",
    "    output_shapes = ([BATCH_SIZE, input_size , input_size, input_channels] , [BATCH_SIZE, ]) # How we're expecting our output shape\n",
    ")\n",
    "\n",
    "tf_val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: val_data , \n",
    "    output_types = (tf.float32 , tf.float32), \n",
    "    output_shapes = ([BATCH_SIZE, input_size, input_size, input_channels] , [BATCH_SIZE, ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to set image_size based on chosen transformer\n",
    "from transformers import ViTFeatureExtractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_id)\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(feature_extractor.size, feature_extractor.size),\n",
    "        layers.Rescaling(1./255),\n",
    "        SwapAxes(-1, 1),\n",
    "        layers.RandomContrast(0.2),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "\n",
    "data_augmentation_for_visualization = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(feature_extractor.size, feature_extractor.size),\n",
    "        layers.RandomContrast(0.2),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "n = 4\n",
    "images = []\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    images.append(np.array(load_patch(X_train_idx[i], DATA_PATH, data='rgb')).reshape(256, 256, 3))\n",
    "\n",
    "for i in range(n):\n",
    "    image = np.array(load_patch(X_train_idx[i], DATA_PATH, data='rgb')).reshape(256, 256, 3)\n",
    "    images.append(data_augmentation_for_visualization(image).numpy())\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    plt.imshow(image.astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for distributed training (that is, using multiple GPUs for data parallelization)\n",
    "# https://www.tensorflow.org/guide/distributed_training#use_tfdistributestrategy_with_keras_modelfit\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFViTModel, TFViTForImageClassification\n",
    "\n",
    "def vit(model_id, input_shape, learning_rate, num_classes, weight_decay_rate):          \n",
    "    # for distributed training\n",
    "    with mirrored_strategy.scope():\n",
    "        # load pre-trained ViT model\n",
    "        base_model = TFViTForImageClassification.from_pretrained(model_id, num_labels=num_classes)\n",
    "        \n",
    "        # Inputs\n",
    "        pixel_values = layers.Input(shape=input_shape, name='pixel_values', dtype='float32')\n",
    "\n",
    "        # Augment data\n",
    "        augmented = data_augmentation(pixel_values)\n",
    "\n",
    "        # Pre-trained ViT model\n",
    "        vit = base_model(augmented)\n",
    "\n",
    "        # Add classification head\n",
    "#         classifier = Dense(num_classes, name='outputs', activation='softmax')(vit.last_hidden_state)\n",
    "\n",
    "        # Define inputs and outputs\n",
    "        model = tf.keras.Model(inputs=pixel_values, outputs=vit.logits)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate, \n",
    "                                         weight_decay=weight_decay_rate)\n",
    "        # Compile model\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=[\n",
    "                          tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "                          tf.keras.metrics.SparseTopKCategoricalAccuracy(10, name=\"top-10-accuracy\")\n",
    "                      ]\n",
    "                      )\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = vit(model_id, \n",
    "            input_shape, \n",
    "            LEARNING_RATE, \n",
    "            NUM_CLASSES, \n",
    "            weight_decay_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    " \n",
    "callbacks=[]\n",
    "\n",
    "# callbacks.append(TensorboardCallback(log_dir=os.path.join(output_dir,\"logs\")))\n",
    "# callbacks.append(EarlyStopping(monitor=\"val_accuracy\",patience=3))\n",
    "callbacks.append(tf.keras.callbacks.ModelCheckpoint('models/vit-{epoch:02d}-{val_loss:0.2f}', \n",
    "                                     monitor='val_loss', \n",
    "                                     verbose=0, \n",
    "                                     save_best_only=True,\n",
    "                                     save_weights_only=False, \n",
    "                                     mode='min', \n",
    "                                     save_freq='epoch'))\n",
    "# if hub_token:\n",
    "#     callbacks.append(PushToHubCallback(output_dir=output_dir,\n",
    "#                                        hub_model_id=hub_model_id,\n",
    "#                                        hub_token=hub_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPU Parallelization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximun value for num_threads is dependent on amount of CPU cores:\n",
    "# amount of CPU cores * vCPUs to core ratio = theoretical max of NUM_THREADS\n",
    "NUM_THREADS = 64\n",
    "\n",
    "# The more batches we prefetch, the less idle the GPUs will be. \n",
    "# To check GPU usage:\n",
    "# 1. Run nvidia-smi -l 1 from the terminal to monitor the GPU usage during training. \n",
    "# 2. Try to get close to 100% for all GPUs by adjusting the value below (and the two above). Due to the overhead\n",
    "#    from tf.distribute.MirroredStrategy(), you won't be able to consistently get 100% for all GPUs. But try to \n",
    "#    get close.\n",
    "# 3. Be aware that RAM limits the amount of batches you can prefetch.\n",
    "PRE_FETCH_NUM_BATCHES = int(NUM_THREADS * 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DATA Auto-sharding policy\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "tf_train_dataset = tf_train_dataset.with_options(options)\n",
    "tf_val_dataset = tf_val_dataset.with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_results = model.fit(\n",
    "    tf_train_dataset.repeat(),\n",
    "    steps_per_epoch=np.floor(len(y_train)/BATCH_SIZE)*2,\n",
    "    validation_data=tf_val_dataset.repeat(),\n",
    "    validation_steps=np.floor(len(y_val)/BATCH_SIZE)*2,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    max_queue_size=PRE_FETCH_NUM_BATCHES, \n",
    "    workers=NUM_THREADS, \n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_results(results):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,6))\n",
    "    axs[0].plot(range(len(results.history['loss'])), results.history['loss'])\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[1].plot(range(len(results.history['val_accuracy'])), results.history['val_accuracy'], label='Validation accuracy')\n",
    "    axs[1].plot(range(len(results.history['val_top-10-accuracy'])), results.history['val_top-10-accuracy'], label='Top-10 Validation accuracy')\n",
    "    axs[1].legend()\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_results(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data using all types of data for an observation\n",
    "train_data = Patches_Generator_Two(X_train_idx, y_train, BATCH_SIZE)\n",
    "val_data = Patches_Generator_Two(X_val_idx, y_val, BATCH_SIZE)\n",
    "\n",
    "# converting our train dataset to tf.data.Dataset\n",
    "tf_train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_data ,  # Our generator \n",
    "    output_types = (tf.float32 , tf.float32) , # How we're expecting our output dtype\n",
    "    output_shapes = ([BATCH_SIZE, input_size , input_size, input_channels] , [BATCH_SIZE, ]) # How we're expecting our output shape\n",
    ")\n",
    "\n",
    "tf_val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: val_data , \n",
    "    output_types = (tf.float32 , tf.float32), \n",
    "    output_shapes = ([BATCH_SIZE, input_size, input_size, input_channels] , [BATCH_SIZE, ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results2 = model.fit(\n",
    "    tf_train_dataset.repeat(),\n",
    "    steps_per_epoch=np.floor(len(y_train)/BATCH_SIZE)*4,\n",
    "    validation_data=tf_val_dataset.repeat(),\n",
    "    validation_steps=np.floor(len(y_val)/BATCH_SIZE)*4,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks,\n",
    "    max_queue_size=PRE_FETCH_NUM_BATCHES, \n",
    "    workers=NUM_THREADS, \n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_results(train_results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()\n",
    "\n",
    "user = api.whoami(hub_token)\n",
    "\n",
    "feature_extractor.save_pretrained(output_dir)\n",
    "\n",
    "api.upload_file(\n",
    "    token=hub_token,\n",
    "    repo_id=f\"{user['name']}/{hub_model_id}\",\n",
    "    path_or_fileobj=os.path.join(output_dir,\"preprocessor_config.json\"),\n",
    "    path_in_repo=\"preprocessor_config.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs_bio = pd.read_csv(DATA_PATH / \"pre-extracted\" / \"environmental_vectors.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_environmental_vars = pd.read_csv(DATA_PATH / \"metadata\" / \"environmental_variables.csv\", sep=\";\", index_col=\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environmental_vars = list(df_environmental_vars['description'])\n",
    "environmental_vars.append('latitude')\n",
    "environmental_vars.append('longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect gps data for selected observations\n",
    "gps_data_train = df_obs.loc[X_train_idx][['latitude', 'longitude']]\n",
    "gps_data_val = df_obs.loc[X_val_idx][['latitude', 'longitude']]\n",
    "\n",
    "# collect biological and pedologic data\n",
    "bio_data_train = df_obs_bio.loc[X_train_idx]\n",
    "bio_data_val = df_obs_bio.loc[X_val_idx]\n",
    "\n",
    "tabular_train = bio_data_train.join(gps_data_train)\n",
    "tabular_val = bio_data_val.join(gps_data_val)\n",
    "\n",
    "n_observations, n_features = tabular_train.shape\n",
    "\n",
    "tabular_train.columns = environmental_vars\n",
    "tabular_val.columns = environmental_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add country feature\n",
    "# tabular_train['country'] = [''] * len(tabular_train)\n",
    "# tabular_val['country'] = [''] * len(tabular_val)\n",
    "\n",
    "# for obs_id in tabular_train.index:\n",
    "#     if obs_id in df_obs_fr.index:\n",
    "#         tabular_train.loc[obs_id, 'country'] = 'France'\n",
    "#     else:\n",
    "#         tabular_train.loc[obs_id, 'country'] = 'United States'\n",
    "# for obs_id in tabular_val.index:\n",
    "#     if obs_id in df_obs_fr.index:\n",
    "#         tabular_val.loc[obs_id, 'country'] = 'France'\n",
    "#     else:\n",
    "#         tabular_val.loc[obs_id, 'country'] = 'United States'\n",
    "\n",
    "# label_col = 'species_id'\n",
    "# label_list = list(set(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT for Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numerical values to strings \n",
    "tabular_train_str = tabular_train.astype(str)\n",
    "tabular_val_str = tabular_val.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column name as token before every cell value\n",
    "for col in tabular_train_str.columns:\n",
    "    tabular_train_str[col] = tabular_train_str[col].map(lambda x: \"<{}> {}\".format(col, x))\n",
    "    tabular_val_str[col] = tabular_val_str[col].map(lambda x: \"<{}> {}\".format(col, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create \"sentences\" from table\n",
    "X_train_tabu = list(tabular_train_str.stack().groupby(level=0).apply(' '.join))\n",
    "X_val_tabu = list(tabular_val_str.stack().groupby(level=0).apply(' '.join))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "BERT_ID = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode text\n",
    "max_length = len(max(X_train_tabu, key = len))\n",
    "\n",
    "def tokenize(sentences, tokenizer, max_length):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer.encode_plus(sentence, add_special_tokens = True, max_length = max_length, pad_to_max_length = True, truncation=True, return_attention_mask = True, return_token_type_ids = True)\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        input_masks.append(inputs['attention_mask'])\n",
    "        input_segments.append(inputs['token_type_ids'])\n",
    "    return np.asarray(input_ids, dtype = \"int32\"), np.asarray(input_masks, dtype = \"int32\"), np.asarray(input_segments, dtype = \"int32\")\n",
    "\n",
    "\n",
    "input_ids, input_masks, input_segments = tokenize(X_train_tabu, tokenizer)\n",
    "val_ids, val_input_masks, val_input_segments = tokenize(X_val_tabu, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "def bert(model_id, learning_rate, num_classes, sentence_length=256):          \n",
    "    # for distributed training\n",
    "#     with mirrored_strategy.scope():\n",
    "    \n",
    "    config = BertConfig(dropout=0, attention_dropout=0)\n",
    "\n",
    "    # load pre-trained BERT model\n",
    "    base_model = TFBertForSequenceClassification.from_pretrained(model_id, config = config)\n",
    "\n",
    "    # Inputs        \n",
    "    input_ids_in = Input(shape=(sentence_length,), name='input_token', dtype=tf.int32)\n",
    "    input_masks_in = Input(shape=(sentence_length,), name='masked_token', dtype=tf.int32) \n",
    "\n",
    "    # Bert Embedding\n",
    "    embedding_layer = base_model(input_ids_in, attention_mask=input_masks_in)[0]\n",
    "\n",
    "    # Add classification head\n",
    "    outputs = layers.Dense(num_classes, name='outputs', activation='softmax')(embedding_layer)\n",
    "\n",
    "    # Define inputs and outputs\n",
    "    model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs=outputs)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)    \n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\n",
    "                      tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "                      tf.keras.metrics.SparseTopKCategoricalAccuracy(10, name=\"top-10-accuracy\")\n",
    "                  ],\n",
    "                  )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = bert(BERT_ID, LEARNING_RATE, NUM_CLASSES, sentence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_input = [\n",
    "    input_ids,\n",
    "    input_masks\n",
    "]\n",
    "\n",
    "bert_val = [\n",
    "    val_ids, \n",
    "    val_input_masks\n",
    "]\n",
    "\n",
    "# need to use SGD to not exceed GPU memory\n",
    "bert_results = bert.fit(\n",
    "    x=bert_input,\n",
    "    y=y_train,\n",
    "    batch_size=2,\n",
    "    validation_data=(bert_val, y_val),\n",
    "    epochs=20,\n",
    "    callbacks=callbacks,\n",
    "    workers=NUM_THREADS, \n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_results(bert_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trying approach from huggingface documentation:** https://huggingface.co/docs/transformers/v4.16.2/en/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "# ds = datasets.Dataset.from_dict({'text': X_train, 'label': y_train})\n",
    "# ds[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# tokenized_datasets = ds.map(tokenize_function, batched=True)\n",
    "\n",
    "# tf_train_dataset = tokenized_datasets.remove_columns(['text']).with_format(\"tensorflow\")\n",
    "\n",
    "# train_features = {x: tf_train_dataset[x] for x in tokenizer.model_input_names}\n",
    "# train_tf_dataset = tf.data.Dataset.from_tensor_slices((train_features, tf_train_dataset[\"label\"]))\n",
    "# train_tf_dataset = train_tf_dataset.shuffle(len(tf_train_dataset)).batch(8)\n",
    "\n",
    "# base_model = TFBertForSequenceClassification.from_pretrained(MODEL_ID, num_labels=NUM_CLASSES)\n",
    "\n",
    "# base_model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    "# )\n",
    "\n",
    "# base_model.fit(train_tf_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# raw_dataset = load_dataset(\"yelp_review_full\")\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# tokenized_datasets = raw_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Yelp\n",
    "# import tensorflow as tf\n",
    "# from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "# small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "# small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "# full_train_dataset = tokenized_datasets[\"train\"]\n",
    "# full_eval_dataset = tokenized_datasets[\"test\"]\n",
    "\n",
    "# tf_train_dataset = small_train_dataset.remove_columns([\"text\"]).with_format(\"tensorflow\")\n",
    "# tf_eval_dataset = small_eval_dataset.remove_columns([\"text\"]).with_format(\"tensorflow\")\n",
    "\n",
    "# train_features = {x: tf_train_dataset[x] for x in tokenizer.model_input_names}\n",
    "# train_tf_dataset = tf.data.Dataset.from_tensor_slices((train_features, tf_train_dataset[\"label\"]))\n",
    "# train_tf_dataset = train_tf_dataset.shuffle(len(tf_train_dataset)).batch(8)\n",
    "\n",
    "# eval_features = {x: tf_eval_dataset[x] for x in tokenizer.model_input_names}\n",
    "# eval_tf_dataset = tf.data.Dataset.from_tensor_slices((eval_features, tf_eval_dataset[\"label\"]))\n",
    "# eval_tf_dataset = eval_tf_dataset.batch(8)\n",
    "\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    "# )\n",
    "\n",
    "# model.fit(train_tf_dataset, validation_data=eval_tf_dataset, epochs=3),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodel CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "\n",
    "    # Inputs\n",
    "    patch_input = layers.Input(shape=(256, 256, 6), dtype='float32')\n",
    "    tabular_input = layers.Input(shape=(29), dtype='float32')  \n",
    "    \n",
    "    # Augment data\n",
    "#     augmented = data_augmentation_for_visualization(patch_input)\n",
    "\n",
    "    # From Scratch model\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(patch_input)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((1, 1), padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)      \n",
    "\n",
    "    # Add Dense layers for images\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    \n",
    "    # Add Dense layers for Tabular data\n",
    "    y = layers.Dense(512, activation='relu')(tabular_input)\n",
    "    y = layers.Dense(256, activation='relu')(y)\n",
    "    \n",
    "    # Concatenate Image and tabular weights\n",
    "    z = layers.Concatenate(axis=1)([x, y])\n",
    "    \n",
    "    # Add Classification Head\n",
    "    z = layers.Dense(128, activation='relu')(z)\n",
    "    classifier = layers.Dense(NUM_CLASSES, name='outputs', activation='softmax')(z)\n",
    "\n",
    "    # Define inputs and outputs\n",
    "    model = tf.keras.Model(inputs=[patch_input, tabular_input], outputs=classifier)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=LEARNING_RATE, \n",
    "                                     weight_decay=weight_decay_rate)\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\n",
    "                      tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "                      tf.keras.metrics.SparseTopKCategoricalAccuracy(10, name=\"top-10-accuracy\")\n",
    "                  ]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches_Generator_CNN(tf.keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, obs_ids, labels, batch_size) :\n",
    "        self.obs_ids = obs_ids\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # to make the generator thread safe \n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.floor(len(self.obs_ids) / float(self.batch_size))).astype(int)\n",
    "  \n",
    "    # returns one batch\n",
    "    def __getitem__(self, idx) :\n",
    "        X_batch = list()\n",
    "        X_env_batch = list()\n",
    "        y_batch = list()\n",
    "\n",
    "        for i in range(idx * self.batch_size, (idx+1) * self.batch_size):\n",
    "            if i >= len(self.obs_ids): break\n",
    "            \n",
    "            rgb, near_ir, landcover, altitude = load_patch(self.obs_ids[i], DATA_PATH)\n",
    "\n",
    "            ni = near_ir.reshape(256, 256, 1)\n",
    "            lc = landcover.reshape(256, 256, 1)\n",
    "            alt = altitude.reshape(256, 256, 1)\n",
    "\n",
    "            patch = np.concatenate((rgb, ni, lc, alt), axis=2)\n",
    "            \n",
    "            X_batch.append(patch)\n",
    "            y_batch.append(self.labels[i])\n",
    "            \n",
    "            X_env_batch.append(tabular_train.loc[self.obs_ids[i]].values)\n",
    "            \n",
    "        with self.lock:\n",
    "            return {'input_1': np.asarray(X_batch), 'input_2': np.asarray(X_env_batch)}, np.asarray(np.array(y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Patches_Generator_CNN(X_train_idx, y_train, BATCH_SIZE)\n",
    "val_data = Patches_Generator_CNN(X_val_idx, y_val, BATCH_SIZE)\n",
    "\n",
    "# converting our train dataset to tf.data.Dataset\n",
    "tf_train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_data ,  # Our generator \n",
    "    output_types = ({'input_1': tf.float32 , 'input_2': tf.float32}, tf.float32) , # How we're expecting our output dtype\n",
    "#     output_shapes = ({'input_1': [BATCH_SIZE, 256 , 256, 6], 'input_2': [BATCH_SIZE, 29]} , [BATCH_SIZE, ]) # How we're expecting our output shape\n",
    ")\n",
    "\n",
    "tf_val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: val_data , \n",
    "    output_types = ({'input_1': tf.float32 , 'input_2': tf.float32}, tf.float32),\n",
    "#     output_shapes = ({'input_1': [BATCH_SIZE, 256 , 256, 6], 'input_2': [BATCH_SIZE, 29]} , [BATCH_SIZE, ]) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_results = model.fit(\n",
    "    tf_train_dataset.repeat(),\n",
    "    steps_per_epoch=np.floor(len(y_train)/BATCH_SIZE)*4,\n",
    "    validation_data=tf_val_dataset.repeat(),\n",
    "    validation_steps=np.floor(len(y_val)/BATCH_SIZE)*4,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    max_queue_size=PRE_FETCH_NUM_BATCHES, \n",
    "    workers=NUM_THREADS, \n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = list(set(X_val_idx) - set(X_train_idx))\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Multi-Modal Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VILBERT_ID = \"uclanlp/visualbert-vqa-coco-pre\"\n",
    "BERT_ID = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Create tokens for text data \n",
    "from transformers import VisualBertModel, AutoTokenizer\n",
    "import datasets\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_ID)\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], max_length=256, padding=\"max_length\", truncation=True)\n",
    "\n",
    "# create huggingface dataset from tabular data\n",
    "ds = datasets.Dataset.from_dict({'text': X_train_tabu, 'label': y_train})\n",
    "\n",
    "# tokenize dataset\n",
    "tokenized_datasets = ds.map(tokenize_function, batched=True)\n",
    "\n",
    "# transform dataset to tensorflow dataset\n",
    "train_tf_dataset = tokenized_datasets.remove_columns(['text']).with_format(\"tensorflow\")\n",
    "train_features = {x: train_tf_dataset[x] for x in tokenizer.model_input_names}\n",
    "text_tokens = tf.data.Dataset.from_tensor_slices((train_features, train_tf_dataset[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Create tokens for images \n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "    \n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 32\n",
    "image_size = 224\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "\n",
    "image = load_patch(X_train_idx[10], DATA_PATH, data='rgb')\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor(image), size=(image_size, image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: How to encode one patch of an image\n",
    "patches = Patches(32)(resized_image)\n",
    "\n",
    "# The PatchEncoder layer will linearly transform a patch by projecting it into a vector of\n",
    "# size projection_dim. In addition, it adds a learnable position embedding to the \n",
    "# projected vector.\n",
    "\n",
    "projection = layers.Dense(units=projection_dim)\n",
    "position_embedding = layers.Embedding(\n",
    "    input_dim=num_patches, output_dim=projection_dim\n",
    ")\n",
    "segment_embedding = layers.Embedding(\n",
    "    input_dim=2, output_dim=projection_dim\n",
    ")\n",
    "\n",
    "patches = patches[0]\n",
    "print(patches.shape)\n",
    "patch = patches[0]\n",
    "positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "print(projection(patches).shape)\n",
    "visual_embeds = projection(patches) + position_embedding(positions) + segment_embedding(1)\n",
    "print(visual_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, VisualBertModel\n",
    "\n",
    "model = VisualBertModel.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"What is the man eating?\", return_tensors=\"pt\")\n",
    "\n",
    "visual_embeds = torch.from_numpy(visual_embeds.numpy()).reshape((1, 49, 64))\n",
    "\n",
    "visual_token_type_ids = torch.ones(visual_embeds.shape[:-1], dtype=torch.long).reshape((1, 49))\n",
    "visual_attention_mask = torch.ones(visual_embeds.shape[:-1], dtype=torch.float).reshape((1, 49))\n",
    "\n",
    "inputs.update(\n",
    "    {\n",
    "        \"visual_embeds\": visual_embeds,\n",
    "        \"visual_token_type_ids\": visual_token_type_ids,\n",
    "        \"visual_attention_mask\": visual_attention_mask,\n",
    "    }\n",
    ")\n",
    "\n",
    "for key in inputs:\n",
    "    print(key, inputs[key].shape)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "last_hidden_state = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_embeds = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from rtdl import NumericalFeatureTokenizer, FTTransformer\n",
    "from transformers import AutoTokenizer \n",
    "\n",
    "num_tokenizer = NumericalFeatureTokenizer(n_features, d_token=3, bias=True, initialization='uniform')\n",
    "\n",
    "tokens = num_tokenizer(torch.tensor(tabular_train.values, dtype=torch.float64))\n",
    "\n",
    "# Look here for more: https://medium.com/georgian-impact-blog/how-to-incorporate-tabular-data-with-huggingface-transformers-b70ac45fcfb4\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "# create dataset\n",
    "torch_dataset = load_data(\n",
    "    tabular_train,\n",
    "    text_cols=text_cols,\n",
    "    numerical_cols=[],\n",
    "    tokenizer = tokenizer,\n",
    "    label_col = 'species_id'\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
